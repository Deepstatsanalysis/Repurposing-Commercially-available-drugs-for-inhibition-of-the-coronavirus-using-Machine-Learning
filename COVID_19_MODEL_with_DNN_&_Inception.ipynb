{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-19_MODEL_with_DNN_&_Inception.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIYKkb0D8ifwIOd9cG8OcE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VIGNESHinZONE/Repurposing-Commercially-available-drugs-for-inhibition-of-the-coronavirus-using-Machine-Learning/blob/master/COVID_19_MODEL_with_DNN_%26_Inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVHtpQ19EmPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cc9e7836-7f66-4488-852a-266744c69315"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK6eUMwdEtVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "944675a2-570a-45eb-d650-26e902fdfeee"
      },
      "source": [
        "cd gdrive/My Drive/SOVID - 19\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1FSDwqpFkKZ8yDznalDgKTEbZSsiUc4Wy/COVID - 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n2FXqGX7vSK",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn-Itko9E2S3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "beb5cc1c-f4a0-49d3-eab9-0813ccbd706d"
      },
      "source": [
        "#General purpose libraries\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Torch Libraries for ANN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "#Sklearn Libraries for Preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7PDjFpOFAEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#seed\n",
        "seed= 12321\n",
        "random.seed(seed)  \n",
        "np.random.seed(0)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6TotH9R71Ff",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyZL8oJlFCCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "e49b53bf-6e72-45e3-f5c5-0aba61a9d3b5"
      },
      "source": [
        "data_train = pd.read_csv('Training_Data_SamR_700.csv').drop(['Unnamed: 0'],axis=1)\n",
        "data_test = pd.read_csv('Testing_data.csv').drop(['Unnamed: 0'],axis=1)\n",
        "data_active_test = data_test[data_test['Outcome']==1]\n",
        "df_drug = pd.read_csv('Drugs.csv')\n",
        "\n",
        "data_train.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NEG_01_NEG</th>\n",
              "      <th>NEG_02_NEG</th>\n",
              "      <th>NEG_03_NEG</th>\n",
              "      <th>NEG_04_NEG</th>\n",
              "      <th>NEG_05_NEG</th>\n",
              "      <th>NEG_06_NEG</th>\n",
              "      <th>NEG_07_NEG</th>\n",
              "      <th>NEG_01_POS</th>\n",
              "      <th>NEG_02_POS</th>\n",
              "      <th>NEG_03_POS</th>\n",
              "      <th>NEG_04_POS</th>\n",
              "      <th>NEG_05_POS</th>\n",
              "      <th>NEG_06_POS</th>\n",
              "      <th>NEG_07_POS</th>\n",
              "      <th>NEG_01_HBD</th>\n",
              "      <th>NEG_02_HBD</th>\n",
              "      <th>NEG_03_HBD</th>\n",
              "      <th>NEG_04_HBD</th>\n",
              "      <th>NEG_05_HBD</th>\n",
              "      <th>NEG_06_HBD</th>\n",
              "      <th>NEG_07_HBD</th>\n",
              "      <th>NEG_01_HBA</th>\n",
              "      <th>NEG_02_HBA</th>\n",
              "      <th>NEG_03_HBA</th>\n",
              "      <th>NEG_04_HBA</th>\n",
              "      <th>NEG_05_HBA</th>\n",
              "      <th>NEG_06_HBA</th>\n",
              "      <th>NEG_07_HBA</th>\n",
              "      <th>NEG_01_ARC</th>\n",
              "      <th>NEG_02_ARC</th>\n",
              "      <th>NEG_03_ARC</th>\n",
              "      <th>NEG_04_ARC</th>\n",
              "      <th>NEG_05_ARC</th>\n",
              "      <th>NEG_06_ARC</th>\n",
              "      <th>NEG_07_ARC</th>\n",
              "      <th>NEG_01_HYP</th>\n",
              "      <th>NEG_02_HYP</th>\n",
              "      <th>NEG_03_HYP</th>\n",
              "      <th>NEG_04_HYP</th>\n",
              "      <th>NEG_05_HYP</th>\n",
              "      <th>...</th>\n",
              "      <th>HYP_01_HYP</th>\n",
              "      <th>HYP_02_HYP</th>\n",
              "      <th>HYP_03_HYP</th>\n",
              "      <th>HYP_04_HYP</th>\n",
              "      <th>HYP_05_HYP</th>\n",
              "      <th>HYP_06_HYP</th>\n",
              "      <th>HYP_07_HYP</th>\n",
              "      <th>WBN_GC_L_0.25</th>\n",
              "      <th>WBN_GC_H_0.25</th>\n",
              "      <th>WBN_GC_L_0.50</th>\n",
              "      <th>WBN_GC_H_0.50</th>\n",
              "      <th>WBN_GC_L_0.75</th>\n",
              "      <th>WBN_GC_H_0.75</th>\n",
              "      <th>WBN_GC_L_1.00</th>\n",
              "      <th>WBN_GC_H_1.00</th>\n",
              "      <th>WBN_EN_L_0.25</th>\n",
              "      <th>WBN_EN_H_0.25</th>\n",
              "      <th>WBN_EN_L_0.50</th>\n",
              "      <th>WBN_EN_H_0.50</th>\n",
              "      <th>WBN_EN_L_0.75</th>\n",
              "      <th>WBN_EN_H_0.75</th>\n",
              "      <th>WBN_EN_L_1.00</th>\n",
              "      <th>WBN_EN_H_1.00</th>\n",
              "      <th>WBN_LP_L_0.25</th>\n",
              "      <th>WBN_LP_H_0.25</th>\n",
              "      <th>WBN_LP_L_0.50</th>\n",
              "      <th>WBN_LP_H_0.50</th>\n",
              "      <th>WBN_LP_L_0.75</th>\n",
              "      <th>WBN_LP_H_0.75</th>\n",
              "      <th>WBN_LP_L_1.00</th>\n",
              "      <th>WBN_LP_H_1.00</th>\n",
              "      <th>XLogP</th>\n",
              "      <th>PSA</th>\n",
              "      <th>NumRot</th>\n",
              "      <th>NumHBA</th>\n",
              "      <th>NumHBD</th>\n",
              "      <th>MW</th>\n",
              "      <th>BBB</th>\n",
              "      <th>BadGroup</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.21896</td>\n",
              "      <td>1.89332</td>\n",
              "      <td>-2.33560</td>\n",
              "      <td>2.37617</td>\n",
              "      <td>-2.81410</td>\n",
              "      <td>3.18823</td>\n",
              "      <td>-3.64319</td>\n",
              "      <td>4.07620</td>\n",
              "      <td>-0.825457</td>\n",
              "      <td>1.36905</td>\n",
              "      <td>-1.69757</td>\n",
              "      <td>2.19638</td>\n",
              "      <td>-2.58817</td>\n",
              "      <td>3.09319</td>\n",
              "      <td>-3.48695</td>\n",
              "      <td>4.01060</td>\n",
              "      <td>-1.108000</td>\n",
              "      <td>1.15249</td>\n",
              "      <td>-1.84816</td>\n",
              "      <td>2.05047</td>\n",
              "      <td>-2.70698</td>\n",
              "      <td>2.96847</td>\n",
              "      <td>-3.59439</td>\n",
              "      <td>3.89453</td>\n",
              "      <td>1.111</td>\n",
              "      <td>90.29</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>369.421</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.05861</td>\n",
              "      <td>2.95213</td>\n",
              "      <td>-2.30022</td>\n",
              "      <td>3.16579</td>\n",
              "      <td>-2.79125</td>\n",
              "      <td>3.49171</td>\n",
              "      <td>-3.46407</td>\n",
              "      <td>4.01080</td>\n",
              "      <td>-0.774518</td>\n",
              "      <td>2.40204</td>\n",
              "      <td>-1.56260</td>\n",
              "      <td>2.67865</td>\n",
              "      <td>-2.35827</td>\n",
              "      <td>3.27843</td>\n",
              "      <td>-3.16100</td>\n",
              "      <td>4.16512</td>\n",
              "      <td>-1.080980</td>\n",
              "      <td>1.07652</td>\n",
              "      <td>-1.91118</td>\n",
              "      <td>1.92376</td>\n",
              "      <td>-2.75759</td>\n",
              "      <td>2.80998</td>\n",
              "      <td>-3.61043</td>\n",
              "      <td>3.71094</td>\n",
              "      <td>3.728</td>\n",
              "      <td>118.91</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>455.414</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.79896</td>\n",
              "      <td>1.23804</td>\n",
              "      <td>-1.94987</td>\n",
              "      <td>1.97407</td>\n",
              "      <td>-2.47040</td>\n",
              "      <td>2.79017</td>\n",
              "      <td>-3.16799</td>\n",
              "      <td>3.63023</td>\n",
              "      <td>-0.775963</td>\n",
              "      <td>1.24417</td>\n",
              "      <td>-1.55582</td>\n",
              "      <td>1.97668</td>\n",
              "      <td>-2.33738</td>\n",
              "      <td>2.80082</td>\n",
              "      <td>-3.11984</td>\n",
              "      <td>3.64791</td>\n",
              "      <td>-0.806244</td>\n",
              "      <td>1.15738</td>\n",
              "      <td>-1.45299</td>\n",
              "      <td>2.00033</td>\n",
              "      <td>-2.15199</td>\n",
              "      <td>2.85873</td>\n",
              "      <td>-2.87913</td>\n",
              "      <td>3.72070</td>\n",
              "      <td>3.332</td>\n",
              "      <td>42.43</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>269.324</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.53969</td>\n",
              "      <td>1.34274</td>\n",
              "      <td>-1.97551</td>\n",
              "      <td>2.07075</td>\n",
              "      <td>-2.75206</td>\n",
              "      <td>2.89920</td>\n",
              "      <td>-3.56623</td>\n",
              "      <td>3.75631</td>\n",
              "      <td>-0.781611</td>\n",
              "      <td>1.36371</td>\n",
              "      <td>-1.58847</td>\n",
              "      <td>2.14600</td>\n",
              "      <td>-2.41639</td>\n",
              "      <td>2.98943</td>\n",
              "      <td>-3.25765</td>\n",
              "      <td>3.85439</td>\n",
              "      <td>-1.035250</td>\n",
              "      <td>1.10898</td>\n",
              "      <td>-1.82384</td>\n",
              "      <td>1.92912</td>\n",
              "      <td>-2.66065</td>\n",
              "      <td>2.78327</td>\n",
              "      <td>-3.51047</td>\n",
              "      <td>3.65414</td>\n",
              "      <td>3.062</td>\n",
              "      <td>53.75</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>221.239</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.04825</td>\n",
              "      <td>1.35043</td>\n",
              "      <td>-1.62054</td>\n",
              "      <td>1.89552</td>\n",
              "      <td>-2.39049</td>\n",
              "      <td>2.55731</td>\n",
              "      <td>-3.17911</td>\n",
              "      <td>3.33711</td>\n",
              "      <td>-0.786468</td>\n",
              "      <td>1.30484</td>\n",
              "      <td>-1.57620</td>\n",
              "      <td>1.91242</td>\n",
              "      <td>-2.36748</td>\n",
              "      <td>2.62653</td>\n",
              "      <td>-3.15964</td>\n",
              "      <td>3.40169</td>\n",
              "      <td>-0.815247</td>\n",
              "      <td>1.11659</td>\n",
              "      <td>-1.40252</td>\n",
              "      <td>1.92860</td>\n",
              "      <td>-2.14519</td>\n",
              "      <td>2.74539</td>\n",
              "      <td>-2.92380</td>\n",
              "      <td>3.56424</td>\n",
              "      <td>6.358</td>\n",
              "      <td>50.41</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>313.470</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 180 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   NEG_01_NEG  NEG_02_NEG  NEG_03_NEG  ...  BBB  BadGroup  Outcome\n",
              "0           0           0           0  ...    0         1      0.0\n",
              "1           0           0           0  ...    0         0      1.0\n",
              "2           0           0           0  ...    1         0      1.0\n",
              "3           0           0           0  ...    1         0      0.0\n",
              "4           0           0           0  ...    1         4      1.0\n",
              "\n",
              "[5 rows x 180 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTXN4hthFWX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = data_train[['Outcome']].to_numpy()\n",
        "X_train = data_train.drop(['Outcome'],axis=1).to_numpy()\n",
        "\n",
        "\n",
        "Y_test = data_test[['Outcome']].to_numpy()\n",
        "X_test = data_test.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_test_active = data_active_test.drop(['Outcome'],axis=1).to_numpy()\n",
        "data_inactive_test = data_test[data_test['Outcome']==0]\n",
        "data_active_train = data_train[data_train['Outcome']==1]\n",
        "data_inactive_train = data_train[data_train['Outcome']==0]\n",
        "X_test_inactive = data_inactive_test.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_train_active = data_active_train.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_train_inactive = data_inactive_train.drop(['Outcome'],axis=1).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L01R0JltF03j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f4fe04d2-f86c-4037-92f3-42d64b2e5280"
      },
      "source": [
        "X_train.shape , Y_train.shape , X_train_active.shape , X_train_inactive.shape , Y_test.shape , X_test.shape , X_test_active.shape , X_test_inactive.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((538343, 179),\n",
              " (538343, 1),\n",
              " (248855, 179),\n",
              " (289488, 179),\n",
              " (1050, 1),\n",
              " (1050, 179),\n",
              " (50, 179),\n",
              " (1000, 179))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYlpN9sC74mR",
        "colab_type": "text"
      },
      "source": [
        "# PCA for data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gtNDbx-GCG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=128)\n",
        "pca.fit(X_train)\n",
        "\n",
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "X_test_active = pca.transform(X_test_active)\n",
        "X_test_inactive = pca.transform(X_test_inactive)\n",
        "X_train_active = pca.transform(X_train_active)\n",
        "X_train_inactive = pca.transform(X_train_inactive)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQFub4-u78uj",
        "colab_type": "text"
      },
      "source": [
        "# Nueral Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1XHUO3pJsVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters\n",
        "activation = 'relu'\n",
        "optimizer = 'Adam'\n",
        "batch_size = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "log_directory = \"runs/logs1\"\n",
        "step = 0\n",
        "writer = SummaryWriter(log_directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK0vJf498D-6",
        "colab_type": "text"
      },
      "source": [
        "# Vanilla DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06HMs8yg8Ax1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Covid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Covid, self).__init__()    \n",
        "                               \n",
        "    self.layer1 = nn.Sequential(nn.Linear(128,512),nn.ReLU(True))\n",
        "    self.layer1_1 = nn.Sequential(nn.Linear(512,1024),nn.ReLU(True))\n",
        "    self.layer2 = nn.Sequential(nn.Linear(1024,512),nn.ReLU(True))\n",
        "    self.layer3 = nn.Sequential(nn.Linear(512,256),nn.ReLU(True))\n",
        "    self.layer4 = nn.Sequential(nn.Linear(256,100),nn.ReLU(True))\n",
        "    self.layer5 = nn.Sequential(nn.Linear(100,1),nn.Sigmoid())\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "\n",
        "  def forward(self,input):\n",
        "\n",
        "    x = (self.layer1(input))\n",
        "    x = self.dropout(self.layer1_1(x))\n",
        "    x = self.dropout(self.layer2(x))\n",
        "    x = self.dropout(self.layer3(x))\n",
        "    x = self.dropout(self.layer4(x))\n",
        "    x = self.layer5(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgyqwfwu8Hba",
        "colab_type": "text"
      },
      "source": [
        "# Inception Convolution Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX5bjdj9Gwtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "class Covidcep(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Covidcep, self).__init__()\n",
        "    \n",
        "           \n",
        "    self.layer1_1 =  nn.Sequential(nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3,padding=1,stride=2),nn.ReLU(True))\n",
        "    self.layer1_2 =  nn.Sequential(nn.Conv1d(1, 4, kernel_size=5,padding=2,stride=2),nn.ReLU(True))\n",
        "    self.layer1_3 = nn.Sequential(nn.Conv1d(1, 4, kernel_size=1,padding=0,stride=1),nn.ReLU(True),nn.MaxPool1d(3,2,1))\n",
        "    self.avgpool1 = nn.AvgPool1d(kernel_size=3,padding=1,stride=1)\n",
        "    \n",
        "    self.layer2_1 = m = nn.Sequential(nn.Conv1d(in_channels=12, out_channels=4, kernel_size=3,padding=1,stride=2),nn.ReLU(True))\n",
        "    self.layer2_2 = m = nn.Sequential(nn.Conv1d(12, 4, kernel_size=5,padding=2,stride=2),nn.ReLU(True))\n",
        "    self.layer2_3 = nn.Sequential(nn.Conv1d(12, 4, kernel_size=1,padding=0,stride=1),nn.ReLU(True),nn.MaxPool1d(3,2,1))\n",
        "    self.avgpool2 = nn.AvgPool1d(kernel_size=3,padding=1,stride=1)\n",
        "         \n",
        "    self.layer3_1 = m = nn.Sequential(nn.Conv1d(in_channels=12, out_channels=3, kernel_size=3,padding=1,stride=2),nn.ReLU(True))\n",
        "    self.layer3_2 = m = nn.Sequential(nn.Conv1d(12, 3, kernel_size=5,padding=2,stride=2),nn.ReLU(True))\n",
        "    self.layer3_3 = nn.Sequential(nn.Conv1d(12, 3, kernel_size=1,padding=0,stride=1),nn.ReLU(True),nn.MaxPool1d(3,2,1))\n",
        "    self.avgpool3 = nn.AvgPool1d(kernel_size=3,padding=1,stride=1)   \n",
        "    \n",
        "    self.layer4 = nn.Sequential(nn.Linear(144,10),nn.ReLU(True))\n",
        "    self.layer5 = nn.Sequential(nn.Linear(10,1),nn.Sigmoid())\n",
        "\n",
        "  def forward(self,x):\n",
        "    \n",
        "    x = torch.unsqueeze(x,1).float()\n",
        "    x = self.avgpool1(torch.cat((self.layer1_1(x), self.layer1_2(x) ,self.layer1_3(x)), 1) )\n",
        "    x = self.avgpool2(torch.cat((self.layer2_1(x), self.layer2_2(x),self.layer2_3(x)), 1) )\n",
        "    x = self.avgpool3(torch.cat((self.layer3_1(x), self.layer3_2(x),self.layer3_3(x)), 1) )\n",
        "    x = x.view(x.size(0),-1).float()\n",
        "    x = self.layer4(x)\n",
        "    x = self.layer5(x)   \n",
        "    \n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYu6G1hy8MYw",
        "colab_type": "text"
      },
      "source": [
        "# Additional Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjsJiwk5JOF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=3, weight=5 , logits=False, reduce=False ):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.weight = weight\n",
        "        self.reduce = reduce\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False , weight=targets*self.weight + 1)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        else:\n",
        "            return torch.sum(F_loss)\n",
        "\n",
        "def train(epoch,train_loader,writer):\n",
        "  model.train()\n",
        "  for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "  train_loss = 0.0\n",
        "  running_loss = 0.0\n",
        "  running_total = 0.0\n",
        "  running_accuracy = 0.0\n",
        "  total = 0.0\n",
        "  accuracy = 0.0\n",
        "  step = 1\n",
        "  print(\"==================================Train==================================\")\n",
        "  for i,data in enumerate(train_loader):\n",
        "    \n",
        "\n",
        "    model.zero_grad()\n",
        "    X_real,Y_real = data\n",
        "    X_real = X_real.to(device).float()\n",
        "    Y_real = Y_real.to(device).float()\n",
        "    b_size = X_real.size(0)\n",
        "    output = model(X_real.float()).float()\n",
        "    \n",
        "    loss = criterion(output.float(), Y_real.float())\n",
        "    loss.backward()\n",
        "    train_loss += loss.item()\n",
        "    running_loss += loss.item()\n",
        "    total += b_size\n",
        "    running_total += b_size\n",
        "\n",
        "\n",
        "    #accuracy\n",
        "    acc = ((Y_real == 1)==((output) > 0.5))\n",
        "    acc = acc.sum().item()\n",
        "    accuracy += acc\n",
        "    running_accuracy += acc\n",
        "    optimizer.step()\n",
        "\n",
        "    if i% 100 == 0 and i!=0:\n",
        "      Tloss,_,_ = test(epoch,test_loader,p = False)\n",
        "      writer.add_scalar('Training_Loss ',\n",
        "                            running_loss/100,\n",
        "                            step )\n",
        "      \n",
        "      writer.add_scalar('Test_Loss ',\n",
        "                            running_accuracy/running_total,\n",
        "                            step )\n",
        "      running_loss = 0.0\n",
        "      running_total = 0.0\n",
        "      running_accuracy = 0.0\n",
        "      step+=1\n",
        "\n",
        "    if i% 500 == 0 and i!=0:\n",
        "      print('[%d/%d][%d/%d]\\tLoss_train: %.4f\\tTrain_Accuracy: %.4f'\n",
        "                  % (epoch, num_epochs, i, len(train_loader),\n",
        "                     loss.item(), acc/b_size))\n",
        "  output = (model(torch.from_numpy(X_train_active).to(device).float())) > 0.5\n",
        "  print(\"Train Active accuracy\" , output.sum().item()/ output.size(0),\"<---------------\")\n",
        "  output = (model(torch.from_numpy(X_train_inactive).to(device).float())) < 0.5\n",
        "  print(\"Train Inactive accuracy\" , output.sum().item()/ output.size(0))\n",
        "  print(\"=========================================================================\")\n",
        "  return train_loss , accuracy/total ,total\n",
        "\n",
        "\n",
        "def test(epoch,test_loader,p = True):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    total = 0.0\n",
        "    accuracy = 0.0\n",
        "    if p:\n",
        "      print(\"==================================Test==================================\")\n",
        "\n",
        "    for i,data in enumerate(test_loader):\n",
        "      X_real,Y_real = data\n",
        "      X_real = X_real.to(device)\n",
        "      Y_real = Y_real.to(device)\n",
        "      b_size = X_real.size(0)\n",
        "      output = model(X_real.float()).float()\n",
        "      loss = criterion(output.float(), Y_real.float())\n",
        "      test_loss += loss.item()\n",
        "      total += b_size\n",
        "\n",
        "      acc = ((Y_real == 1)==((output) > 0.5))\n",
        "      acc = acc.sum().item() / b_size\n",
        "      accuracy += acc\n",
        "\n",
        "      if i% 3 == 0 and i!=0 and p:\n",
        "        print('[%d/%d][%d/%d]\\tLoss_test: %.4f\\tTest_Accuracy: %.4f'\n",
        "                  % (epoch, num_epochs, i, len(test_loader),\n",
        "                     loss.item(), acc))\n",
        "      \n",
        "\n",
        "    output = (model(torch.from_numpy(X_test_active).to(device).float())) > 0.5\n",
        "    if p:\n",
        "      print(\"Test Active accuracy\" , output.sum().item()/ output.size(0),\"<---------------\")\n",
        "    output = (model(torch.from_numpy(X_test_inactive).to(device).float())) < 0.5\n",
        "    if p:\n",
        "      print(\"Test Inactive accuracy\" , output.sum().item()/ output.size(0))\n",
        "      print(\"=========================================================================\")\n",
        "    return test_loss,accuracy,total\n",
        "\n",
        "\n",
        "def compute_roc(y_true, y_pred, plot=True):\n",
        "    \"\"\"\n",
        "    TODO\n",
        "    :param y_true: ground truth\n",
        "    :param y_pred: predictions\n",
        "    :param plot:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_true, y_pred)\n",
        "    auc_score = metrics.auc(fpr, tpr)\n",
        "    if plot:\n",
        "        plt.figure(figsize=(7, 6))\n",
        "        plt.plot(fpr, tpr, color='blue',\n",
        "                 label='ROC (AUC = %0.4f)' % auc_score)\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.title(\"ROC Curve\")\n",
        "        plt.xlabel(\"FPR\")\n",
        "        plt.ylabel(\"TPR\")\n",
        "        plt.show()\n",
        "\n",
        "    return fpr, tpr, auc_score \n",
        "\n",
        "def drug_checker(arr,conf):\n",
        "  ls = [1082,928,115,1260,794,573,1133,383,1112,1919,1918,1750]\n",
        "  for e in  ls:\n",
        "    if e in arr:\n",
        "      print( \"Drug number \", e , \" score \", conf[e])\n",
        "\n",
        "def drug_checker_all(arr,conf):\n",
        "  ls = [1082,928,115,1260,794,573,1133,383,1112,1919,1918,1750]\n",
        "  for e in  ls:\n",
        "    \n",
        "      print( \"Drug number \", e , \" score \", conf[e])\n",
        "\n",
        "                  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBaHNvg1TN-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).float())\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test).float())\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je83SJ1a8RMs",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "## Vanilla DNN with BCELoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gOTDg3ZM4pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "58d7517a-9b6f-4c3d-f675-20cd27eb7db4"
      },
      "source": [
        "num_epochs = 2\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "model = Covid()\n",
        "model = model.to(device).float()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 5e-5)\n",
        "\n",
        "for epoch in range(0, num_epochs ):\n",
        "    a, _,c = train(epoch,train_loader,writer)\n",
        "    i,_,e = test(epoch,test_loader)\n",
        "    \n",
        "model.eval()\n",
        "X_drug = df_drug.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_drug = pca.transform(X_drug)\n",
        "\n",
        "output = (model(torch.from_numpy(X_drug).to(device).float())) > 0.5\n",
        "print( \"drugs\",output.sum().item())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================Train==================================\n",
            "[0/2][500/2103]\tLoss_train: 0.5783\tTrain_Accuracy: 0.7070\n",
            "[0/2][1000/2103]\tLoss_train: 0.4921\tTrain_Accuracy: 0.7461\n",
            "[0/2][1500/2103]\tLoss_train: 0.4013\tTrain_Accuracy: 0.8086\n",
            "[0/2][2000/2103]\tLoss_train: 0.3356\tTrain_Accuracy: 0.8398\n",
            "Train Active accuracy 0.9690140845070423 <---------------\n",
            "Train Inactive accuracy 0.8080334936163157\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[0/2][3/5]\tLoss_test: 0.4400\tTest_Accuracy: 0.8320\n",
            "Test Active accuracy 0.64 <---------------\n",
            "Test Inactive accuracy 0.79\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[1/2][500/2103]\tLoss_train: 0.2624\tTrain_Accuracy: 0.9102\n",
            "[1/2][1000/2103]\tLoss_train: 0.1429\tTrain_Accuracy: 0.9609\n",
            "[1/2][1500/2103]\tLoss_train: 0.1845\tTrain_Accuracy: 0.9297\n",
            "[1/2][2000/2103]\tLoss_train: 0.1337\tTrain_Accuracy: 0.9414\n",
            "Train Active accuracy 0.9971830985915493 <---------------\n",
            "Train Inactive accuracy 0.9154541811750401\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[1/2][3/5]\tLoss_test: 0.2432\tTest_Accuracy: 0.9297\n",
            "Test Active accuracy 0.4 <---------------\n",
            "Test Inactive accuracy 0.92\n",
            "=========================================================================\n",
            "drugs 210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWWDilc2TBOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "ac370c40-a147-4811-c7d2-f11d93298df4"
      },
      "source": [
        "_,_,_=compute_roc(Y_test,model(torch.from_numpy(X_test).to(device).float()).cpu().detach().numpy())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAGDCAYAAAC2tW7jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5SddX3v8feXmwEBxQQ4kIu5cE0CDjjciiWxIkTkdhAxQAtUbaxC0YPHVSpHBZRlq61FIGqnl2W1JFzKKokVmlpuInILEhAS4YSAMgEOaSAggUgu3/PH3hkmk5nJJNm3+c37tdZe7OfZv+z9nWdN+OT3PN/9eyIzkSSpRNs0uwBJkurFkJMkFcuQkyQVy5CTJBXLkJMkFcuQkyQVy5CTJBXLkJO2QkQ8ExFvRMRrEfFCRHw/InbuMeb3IuL2iPhtRLwSET+KiIk9xuwaEVdGxG+q7/VUdXtEH58bEXFhRDwWESsjojMiboyIg+r580qDjSEnbb2TMnNnoA04BPiL9S9ExFHAfwJzgL2BccAjwD0RMb46ZgfgNmASMA3YFTgKWA4c3sdnfhv4LHAh8C5gP+Bm4MObW3xEbLe5f0YaLMIVT6QtFxHPAJ/MzP+qbn8DmJSZH65u3w38MjM/0+PP3Qosy8xzIuKTwBXAhMx8bQCfuS/wK+CozHygjzF3Av+Smf9Q3T6vWuf7qtsJXAB8DtgO+A9gZWb+727vMQe4KzO/FRF7A1cDxwCvAX+bmVcN4BBJTeVMTqqRiBgFfAhYXN3eCfg94MZeht8AfLD6/FjgPwYScFUfADr7CrjNcCpwBDARmA18LCICICJ2A44DrouIbYAfUZmBjqx+/uci4vit/Hyp7gw5aevdHBG/BZ4FXgS+Ut3/Lip/x57v5c88D6y/3ja8jzF92dzxffl6Zr6UmW8AdwMJ/H71tdOBezPzOeAwYPfMvDwz38zMJcDfA9NrUINUV4actPVOzcxdgKnAAbwVXi8D64C9evkzewH/XX2+vI8xfdnc8X15dv2TrFy3uA44s7rrLODa6vN3A3tHxIr1D+CLwJ41qEGqK0NOqpHMvAv4PvDX1e2VwL3AR3sZfgaVZhOA/wKOj4i3D/CjbgNGRUR7P2NWAjt12/4fvZXcY3s2cHpEvJvKacybqvufBZ7OzHd2e+ySmScMsF6paQw5qbauBD4YEe+pbl8MnFtt998lInaLiK9R6Z68rDrmh1SC5KaIOCAitomI4RHxxYjYKEgy8/8C3wFmR8TUiNghIoZFxPSIuLg6bAFwWkTsFBH7AJ/YVOGZ+TCV2eU/APMyc0X1pQeA30bEn0fEjhGxbURMjojDtuQASY1kyEk1lJnLgB8AX65u/ww4HjiNynW0X1P5msH7qmFFZv6OSvPJr4CfAK9SCZYRwP19fNSFwDXATGAF8BTwP6k0iAD8LfAm8P+Af+atU4+bMqtay6xuP9Na4EQqX5F4mreC8B0DfE+pafwKgSSpWM7kJEnFMuQkScUy5CRJxTLkJEnFMuQkScUadKuPjxgxIseOHdvsMiRJLeShhx7678zcvef+QRdyY8eOZf78+c0uQ5LUQiLi173t93SlJKlYhpwkqViGnCSpWIacJKlYhpwkqViGnCSpWIacJKlYhpwkqViGnCSpWHULuYj4p4h4MSIe6+P1iIirImJxRDwaEYfWqxZJ0tBUz5nc94Fp/bz+IWDf6mMG8N061iJJGoLqtnZlZv40Isb2M+QU4AeZmcB9EfHOiNgrM5+vV02SVLqODpg1q9lVDFxbG1x5Zf3ev5nX5EYCz3bb7qzu20hEzIiI+RExf9myZQ0pTpIGo1mzYMGCZlfROgbFXQgyswPoAGhvb88mlyNJLa2tDe68s9lVtIZmzuSWAqO7bY+q7pMkqSaaGXJzgXOqXZZHAq94PU6SVEt1O10ZEbOBqcCIiOgEvgJsD5CZ3wNuAU4AFgOvA39cr1okSUNTPbsrz9zE6wmcX6/Pl6TBbEu7JBcsqFyTU4UrnkhSC9rSLsm2NjjrrNrXM1gNiu5KSRqK7JLces7kJEnFMuQkScUy5CRJxfKanCQ10EC7Ju2SrA1ncpLUQAPtmrRLsjacyUlSg9k12TjO5CRJxTLkJEnFMuQkScXympwk9aEed9m2a7KxnMlJUh/qcZdtuyYby5mcJPXDTsjBzZmcJKlYhpwkqViGnCSpWIacJHXT0QFTp1YetW46UeMZcpLUTfeOSjshBz+7KyWpBzsqy+FMTpJULENOklQsQ06SVCyvyUka9Gq5xqRrS5bFmZykQa+Wa0zaUVkWZ3KSimBHpHrjTE6SVCxDTpJULENOklQsQ07SoOQakxoIQ07SoOQakxoIuyslDVp2VGpTnMlJkoplyEmSimXISZKKZchJkoplyEmSimXISZKKZchJkoplyEmSimXISZKK5YonkppuS+7s7R28NRDO5CQ13Zbc2dv1KjUQzuQktQTXoVQ9OJOTJBXLkJMkFcuQkyQVy2tykjawJZ2OW8tOSdWLMzlJG9iSTsetZaek6sWZnKSN2OmoUtR1JhcR0yLiiYhYHBEX9/L6mIi4IyIejohHI+KEetYjSRpa6hZyEbEtMBP4EDARODMiJvYY9n+AGzLzEGA68J161SNJGnrqOZM7HFicmUsy803gOuCUHmMS2LX6/B3Ac3WsR5I0xNTzmtxI4Nlu253AET3GXAr8Z0T8GfB24Ng61iMVq5YdkXY6qiTN7q48E/h+Zo4CTgB+GBEb1RQRMyJifkTMX7ZsWcOLlFpdLTsi7XRUSeo5k1sKjO62Paq6r7tPANMAMvPeiBgGjABe7D4oMzuADoD29vasV8HSYGZHpLSxes7kHgT2jYhxEbEDlcaSuT3G/Ab4AEBEHAgMA5yqSZJqom4hl5lrgAuAecAiKl2Uj0fE5RFxcnXY54E/iYhHgNnAeZnpTE2SVBN1/TJ4Zt4C3NJj35e7PV8IHF3PGiRJQ5crnkgtaHO7Je2IlHrX7O5KSb3Y3G5JOyKl3jmTk1qU3ZLS1nMmJ0kqliEnSSqWISdJKpbX5KQG2ZyOSbslpdpwJic1yOZ0TNotKdWGMzmpgeyYlBrLmZwkqViGnCSpWIacJKlYXpOTaqyvLko7JqXGcyYn1VhfXZR2TEqN50xOqgO7KKXW4ExOklQsQ06SVCxDTqqRjg6YOnXz7gMnqb4MOalG1jec2GAitQ4bT6QasuFEai3O5CRJxTLkJEnFMuQkScUy5CRJxTLkJEnFMuQkScUy5CRJxTLkJEnFMuQkScVyxRO1tL5uQNqKvCmq1Hqcyaml9XUD0lbkmpVS63Emp5bnepCStpQzOUlSsQw5SVKxDDlJUrG8JqeW0rOb0o5FSVvDmZxaSs9uSjsWJW0NZ3JqOXZTSqoVZ3KSpGIZcpKkYhlykqRieU1OTdHXmpR2U0qqJWdyaoq+1qS0m1JSLTmTU9PYRSmp3pzJSZKKZchJkoplyEmSimXIqWE6OmDq1MpjsNwIVdLgZsipYbp3VNpFKakR7K5UQ9lRKamRnMlJkopV15CLiGkR8URELI6Ii/sYc0ZELIyIxyOilzUwJEnaMnU7XRkR2wIzgQ8CncCDETE3Mxd2G7Mv8BfA0Zn5ckTsUa96JElDTz2vyR0OLM7MJQARcR1wCrCw25g/AWZm5ssAmfliHetRDfW19mR/XJdSUqPV83TlSODZbtud1X3d7QfsFxH3RMR9ETGttzeKiBkRMT8i5i9btqxO5Wpz9LX2ZH/sqJTUaM3urtwO2BeYCowCfhoRB2Xmiu6DMrMD6ABob2/PRhep3tkpKanV1XMmtxQY3W17VHVfd53A3MxcnZlPA09SCT1JkrZaPUPuQWDfiBgXETsA04G5PcbcTGUWR0SMoHL6ckkda5IkDSF1C7nMXANcAMwDFgE3ZObjEXF5RJxcHTYPWB4RC4E7gC9k5vJ61SRJGlrqek0uM28Bbumx78vdnidwUfWhQaKjA+66C6ZMaXYlktQ/VzzRZlv/1QE7JSW1OkNOW2TKFJgxo9lVSFL/DDlJUrEMOUlSsQw5SVKxDDkNiHf1ljQYGXIaEO/qLWkwavbalRpEXKtS0mDjTE6SVCxDTpJULENOklQsr8lpI73d9du7eksajJzJaSO93fXbjkpJg5EzOfXKTkpJJXAmJ0kqliEnSSrWZodcRGwTEWfXoxhJkmqpz5CLiF0j4i8i4pqIOC4q/gxYApzRuBLVSOvv+i1JJeiv8eSHwMvAvcAngS8CAZyamS7RWyjv+i2pJP2F3PjMPAggIv4BeB4Yk5mrGlKZmsa7fksqRX/X5Favf5KZa4FOA06SNJj0N5N7T0S8SuUUJcCO3bYzM3ete3WSJG2FPkMuM7dtZCGSJNVaf92VwyLic9XuyhkR4eoohbOzUlJp+rsm989AO/BL4ATgbxpSkZrGzkpJpelvdjaxW3flPwIPNKYkNZOdlZJKMtDuyjUNqEWSpJrqbybXVu2mhEpHpd2VkqRBpb+QeyQzD2lYJZIk1Vh/IZcNq0Jbrbe7eW8u7/4tqTT9hdweEXFRXy9m5rfqUI+20Pq7eW9NSHn3b0ml6S/ktgV25q0VT9TivJu3JG2ov5B7PjMvb1glkiTVWH9fIXAGJ0ka1PoLuQ80rApJkuqgz5DLzJcaWYg2X0cHTJ1aeSzwNraStJH+ZnJqces7KsHOSEnqjXcWGOTsqJSkvjmTkyQVy5CTJBXLkJMkFctrci1mc9agdK1JSeqfM7kW071jclPsqJSk/jmTa0F2TEpSbTiTkyQVy5CTJBXL05VN0F9zic0kklQ7zuSaoL/mEptJJKl2nMk1ic0lklR/zuQkScWqa8hFxLSIeCIiFkfExf2M+0hEZES017MeSdLQUreQi4htgZnAh4CJwJkRMbGXcbsAnwXur1ctkqShqZ7X5A4HFmfmEoCIuA44BVjYY9xXgb8CvlDHWpqmt05KOyglqTHqebpyJPBst+3O6r4uEXEoMDozf9zfG0XEjIiYHxHzly1bVvtK66i3Tko7KCWpMZrWXRkR2wDfAs7b1NjM7AA6ANrb27O+ldWenZSS1Bz1nMktBUZ32x5V3bfeLsBk4M6IeAY4Ephr84kkqVbqGXIPAvtGxLiI2AGYDsxd/2JmvpKZIzJzbGaOBe4DTs7M+XWsSZI0hNQt5DJzDXABMA9YBNyQmY9HxOURcXK9PleSpPXqek0uM28Bbumx78t9jJ1az1qaoaMD7roLpkxpdiWSNDS54kkdrf/qgJ2UktQchlydTZkCM2Y0uwpJGpoMOUlSsQw5SVKxDDlJUrG8n1wN9HWnb9eolKTmciZXA33d6ds1KiWpuZzJ1YjrU0pS63EmJ0kqliEnSSqWISdJKpYht5XWr08pSWo9htxWcn1KSWpdhlwNuD6lJLUmQ06SVCxDTpJULENOklQsVzwZINenlKTBx5ncALk+pSQNPs7kNoPrU0rS4OJMTpJULENOklQsQ06SVCyvyfWhZzelXZSSNPg4k+tDz25KuyglafBxJtcPuyklaXBzJidJKpYhJ0kqliEnSSqWIdcL7/YtSWUw5Hrh3b4lqQyGXB+827ckDX6GnCSpWIacJKlYhpwkqViGXA92VkpSOQy5HuyslKRyGHK9sLNSkspgyEmSimXISZKKZchJkoplyHVjZ6UklcWQ68bOSkkqiyHXg52VklQOQ06SVCxDTpJULENOklQsQ45KV+XUqbBgQbMrkSTVkiFHpatywQJoa7OzUpJKsl2zC2gVbW1w553NrkKSVEt1nclFxLSIeCIiFkfExb28flFELIyIRyPitoh4dz3rkSQNLXULuYjYFpgJfAiYCJwZERN7DHsYaM/Mg4F/Bb5Rr3okSUNPPWdyhwOLM3NJZr4JXAec0n1AZt6Rma9XN+8DRtWxHknSEFPPkBsJPNttu7O6ry+fAG6tYz2SpCGmJRpPIuIPgXZgSh+vzwBmAIwZM6aBlUmSBrN6zuSWAqO7bY+q7ttARBwLXAKcnJm/6+2NMrMjM9szs3333XevS7GSpPLUM+QeBPaNiHERsQMwHZjbfUBEHAL8HZWAe7GOtUiShqC6hVxmrgEuAOYBi4AbMvPxiLg8Ik6uDvsmsDNwY0QsiIi5fbydJEmbra7X5DLzFuCWHvu+3O35sfX8fEnS0OayXpKkYhlykqRiGXKSpGIZcpKkYhlykqRiGXKSpGIZcpKkYhlykqRiGXKSpGIZcpKkYhlykqRiDfmQ6+iAu+5qdhWSpHoY8iE3a1blv2ed1dw6JEm1N+RDDmDKFJgxo9lVSJJqzZCTJBXLkJMkFcuQkyQVy5CTJBXLkJMkFcuQkyQVy5CTJBXLkJMkFcuQkyQVa0iHnOtWSlLZhnTIuW6lJJVtSIccuG6lJJVsyIecJKlchpwkqViGnCSpWEMy5Do6YOpUWLCg2ZVIkuppSIbcrFmVgGtrs7NSkkq2XbMLaJa2NrjzzmZXIUmqpyE5k5MkDQ2GnCSpWIacJKlYhpwkqViGnCSpWIacJKlYhpwkqViGnCSpWIacJKlYhpwkqViGnCSpWIacJKlYhpwkqViGnCSpWEP2VjuSWsvq1avp7Oxk1apVzS5FLWzYsGGMGjWK7bfffkDjDTlJLaGzs5NddtmFsWPHEhHNLkctKDNZvnw5nZ2djBs3bkB/xtOVklrCqlWrGD58uAGnPkUEw4cP36zZviEnqWUYcNqUzf0dMeQkScWqa8hFxLSIeCIiFkfExb28/raIuL76+v0RMbae9UhSf7bddlva2tqYPHkyJ510EitWrOh67fHHH+cP/uAP2H///dl333356le/SmZ2vX7rrbfS3t7OxIkTOeSQQ/j85z/f62fcfPPNXH755Rvsa2trY/r06Rvsmzp1KvPnz+/afuaZZ5g8eXLX9gMPPMAxxxzD/vvvzyGHHMInP/lJXn/99a36+Z9++mmOOOII9tlnHz72sY/x5ptvbjTm2muvpa2treuxzTbbsGDBAgCmTZvGe97zHiZNmsSf/umfsnbtWgC+9KUvcfDBB9PW1sZxxx3Hc889B1SusV144YXss88+HHzwwfziF78AYNmyZUybNm2rfpYumVmXB7At8BQwHtgBeASY2GPMZ4DvVZ9PB67f1Pu+973vza01ZUrlIal1LFy4sNkl5Nvf/vau5+ecc05+7Wtfy8zM119/PcePH5/z5s3LzMyVK1fmtGnT8pprrsnMzF/+8pc5fvz4XLRoUWZmrlmzJr/zne/0+hlHHXVULlu2rGt74cKFOXny5Nx7773ztdde69o/ZcqUfPDBB7u2n3766Zw0aVJmZr7wwgs5ZsyY/PnPf971+o033pgvvPDCVv38H/3oR3P27NmZmfmpT32qz59hvUcffTTHjx/ftf3KK69kZua6devytNNO63qv9fszM7/97W/npz71qczM/PGPf5zTpk3LdevW5b333puHH35417jzzjsvf/azn/X6ub39rgDzs5fMqGd35eHA4sxcAhAR1wGnAAu7jTkFuLT6/F+BayIiqgVLGqI+9zmoTg5qpq0Nrrxy4OOPOuooHn30UQBmzZrF0UcfzXHHHQfATjvtxDXXXMPUqVM5//zz+cY3vsEll1zCAQccAFRmhJ/+9Kc3es8nn3ySt73tbYwYMaJr3+zZs/mjP/ojFi1axJw5czjrrLM2WdvMmTM599xzOeqoo7r2nX766QP/4XqRmdx+++3MmjULgHPPPZdLL72015+je+3dZ6C77rorAGvWrOHNN9/sun62fj/AypUru/bPmTOHc845h4jgyCOPZMWKFTz//PPstddenHrqqVx77bUcffTRW/Vz1fN05Ujg2W7bndV9vY7JzDXAK8Dwnm8UETMiYn5EzF+2bNlWF9bWVnlIUm/Wrl3LbbfdxsknnwxUTlW+973v3WDMhAkTeO2113j11Vd57LHHNnq9N/fccw+HHnroBvuuv/56pk+fzplnnsns2bMHVN9AP++JJ57Y4NRi90f3U7EAy5cv553vfCfbbVeZ+4waNYqlS5f2+/7XX389Z5555gb7jj/+ePbYYw922WWXDYL3kksuYfTo0Vx77bVdp2uXLl3K6NGju8Z0/8z29nbuvvvuTf6MmzIovieXmR1AB0B7e/tWz/I2519zkhqvWX9H33jjDdra2li6dCkHHnggH/zgB2v6/s8//zy777571/b8+fMZMWIEY8aMYeTIkXz84x/npZde4l3velevXYSb21m4//77d10vq7X777+fnXbaaYPrhADz5s1j1apVnH322dx+++1dx/CKK67giiuu4Otf/zrXXHMNl112Wb/vv8cee3Rdu9sa9ZzJLQVGd9seVd3X65iI2A54B7C8jjVJUp923HFHFixYwK9//Wsyk5kzZwIwceJEHnrooQ3GLlmyhJ133pldd92VSZMmbfR6X+/f/Ttes2fP5le/+hVjx45lwoQJvPrqq9x0000ADB8+nJdffrlr7EsvvdR1mnOgn7c5M7nhw4ezYsUK1qxZA1S+nD9yZM+Tb2+57rrrNprFrTds2DBOOeUU5syZs9FrZ599dtfPOHLkSJ599q0Tft0/c9WqVey4446b/Bk3qbcLdbV4UJklLgHG8VbjyaQeY85nw8aTGzb1vrVoPJHUelqt8eQXv/hFjhkzJlevXp2vv/56jhs3Ln/yk59kZqUR5cMf/nBeddVVmZn5yCOP5IQJE/KJJ57IzMy1a9fmd7/73Y3e/9Zbb82zzz67a8yoUaNy6dKlXa/ffvvt+f73vz8zM6+++uo855xzct26dZmZeeGFF+Zll12WmW81ntx3331df/amm27a6saT008/fYPGk5kzZ/Y6bu3atbn33nvnU0891bXvt7/9bT733HOZmbl69eo844wz8uqrr87MzCeffLJr3FVXXZUf+chHMjPz3//93zdoPDnssMO6xs2fPz+PP/74Xj9/cxpP6hZylc/kBOBJKl2Wl1T3XQ6cXH0+DLgRWAw8AIzf1HsaclKZWi3kMjNPPPHE/MEPfpCZlU7CKVOm5H777ZcTJkzISy+9tCuAMjN/9KMf5aGHHpoHHHBAHnjggfmFL3xho/dfuXJlTpw4MdetW5d33nlnHnHEERu8vmbNmtxzzz3zueeey9/97nd5/vnn50EHHZQHH3xwfvzjH8+VK1d2jf35z3+e73vf+3K//fbLAw44IGfMmLHB61viqaeeysMOOywnTJiQp59+eq5atSozM+fMmZNf+tKXusbdcccdG9X+wgsvZHt7ex500EE5adKkvOCCC3L16tWZmXnaaaflpEmT8qCDDsoTTzwxOzs7M7PShfmZz3wmx48fn5MnT96gm/Sb3/xm1z8ietqckIscZI2M7e3t2f27I5LKsGjRIg488MBml1F3n/3sZznppJM49thjm11KSzvmmGOYM2cOu+2220av9fa7EhEPZWZ7z7GueCJJDfTFL35xq7+0Xbply5Zx0UUX9Rpwm8uQk6QG2nPPPbu+mqDe7b777px66qk1eS9DTlLLGGyXT9R4m/s7YshJagnDhg1j+fLlBp36lFm5n9ywYcMG/GcGxZfBJZVv1KhRdHZ2UotVjVSu9XcGHyhDTlJL2H777Qd8t2dpoDxdKUkqliEnSSqWISdJKtagW/EkIpYBv67BW40A/rsG71Mij03fPDZ989j0zWPTt1odm3dn5u49dw66kKuViJjf2xIw8tj0x2PTN49N3zw2fav3sfF0pSSpWIacJKlYQznkOppdQAvz2PTNY9M3j03fPDZ9q+uxGbLX5CRJ5RvKMzlJUuGKD7mImBYRT0TE4oi4uJfX3xYR11dfvz8ixja+yuYYwLG5KCIWRsSjEXFbRLy7GXU2w6aOTbdxH4mIjIgh0zk3kGMTEWdUf3cej4hZja6xWQbwd2pMRNwREQ9X/16d0Iw6Gy0i/ikiXoyIx/p4PSLiqupxezQiDq3Zh/d2u/BSHsC2wFPAeGAH4BFgYo8xnwG+V30+Hbi+2XW30LF5P7BT9fmnPTYbjdsF+ClwH9De7Lpb5dgA+wIPA7tVt/dodt0tdGw6gE9Xn08Enml23Q06NscAhwKP9fH6CcCtQABHAvfX6rNLn8kdDizOzCWZ+SZwHXBKjzGnAP9cff6vwAciIhpYY7Ns8thk5h2Zuf4WxvcBA1/6e3AbyO8NwFeBvwJWNbK4JhvIsfkTYGZmvgyQmS82uMZmGcixSWDX6vN3AM81sL6mycyfAi/1M+QU4AdZcR/wzojYqxafXXrIjQSe7bbdWd3X65jMXAO8AgxvSHXNNZBj090nqPxLayjY5LGpnk4ZnZk/bmRhLWAgvzf7AftFxD0RcV9ETGtYdc01kGNzKfCHEdEJ3AL8WWNKa3mb+/+jAfNWO9qkiPhDoB2Y0uxaWkFEbAN8CzivyaW0qu2onLKcSmX2/9OIOCgzVzS1qtZwJvD9zPybiDgK+GFETM7Mdc0urFSlz+SWAqO7bY+q7ut1TERsR+UUwvKGVNdcAzk2RMSxwCXAyZn5uwbV1mybOja7AJOBOyPiGSrXEOYOkeaTgfzedAJzM3N1Zj4NPEkl9Eo3kGPzCeAGgMy8FxhGZe3GoW5A/z/aEqWH3IPAvhExLiJ2oNJYMrfHmLnAudXnpwO3Z/VKaOE2eWwi4hDg76gE3FC5rgKbODaZ+UpmjsjMsZk5lsr1ypMzc35zym2ogfydupnKLI6IGEHl9OWSRhbZJAM5Nr8BPgAQEQdSCTlvhV45TudUuyyPBF7JzOdr8cZFn67MzDURcQEwj0rn0z9l5uMRcTkwPzPnAv9I5ZTBYioXRqc3r+LGGeCx+SawM3BjtRfnN5l5ctOKbpABHpshaYDHZh5wXEQsBNYCX8jM4s+ODPDYfB74+4j4X1SaUM4bCv+ojojZVP7hM6J6PfIrwPYAmfk9KtcnTwAWA68Df1yzzx4Cx1eSNESVfrpSkjSEGXKSpGIZcpKkYhlykqRiGXKSpGIZclKLioi1EbGg22NsREyNiFeq24si4ivVsd33/yoi/rrZ9UutoOjvyUmD3BuZ2dZ9R/VWUHdn5okR8XZgQUT8qPry+v07Ag9HxL9l5j2NLUOimsYAAADLSURBVFlqLc7kpEEqM1cCDwH79Nj/BrCAGi1wKw1mhpzUunbsdqry33q+GBHDqayb+XiP/btRWSvyp40pU2pdnq6UWtdGpyurfj8iHgbWAX9ZXTpqanX/I1QC7srMfKGBtUotyZCTBp+7M/PEvvZHxDjgvoi4ITMXNLo4qZV4ulIqTPX2Nn8J/Hmza5GazZCTyvQ94JhqN6Y0ZHkXAklSsZzJSZKKZchJkoplyEmSimXISZKKZchJkoplyEmSimXISZKKZchJkor1/wEOaISdFTaLEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY9yKAwATlUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "26748509-3363-4102-a3a7-e9c82bd3276a"
      },
      "source": [
        "ans = output.cpu().detach().numpy()\n",
        "result = np.where(ans == True)\n",
        "drug_df = pd.read_csv('Drug1.csv')\n",
        "list_df = drug_df[['DRUGBANK_ID']]\n",
        "list_df = list_df.iloc[result[0].tolist()]\n",
        "conf = model(torch.from_numpy(X_drug).to(device).float()).cpu().detach().numpy()\n",
        "drug_checker(result[0],conf)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drug number  928  score  [0.9994011]\n",
            "Drug number  1260  score  [0.9896063]\n",
            "Drug number  573  score  [0.8190205]\n",
            "Drug number  383  score  [0.9999453]\n",
            "Drug number  1112  score  [0.8803262]\n",
            "Drug number  1918  score  [0.99996555]\n",
            "Drug number  1750  score  [0.9999145]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b805R2BM8czg",
        "colab_type": "text"
      },
      "source": [
        "# Vanilla DNN with weighted Focal loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PysxTG2hWB15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "74bb03b3-9f2f-463d-f874-b045391fdd46"
      },
      "source": [
        "num_epochs = 3\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "model = Covid()\n",
        "model = model.to(device).float()\n",
        "criterion = FocalLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 5e-5)\n",
        "\n",
        "for epoch in range(0, num_epochs ):\n",
        "    a, _,c = train(epoch,train_loader,writer)\n",
        "    i,_,e = test(epoch,test_loader)\n",
        "    \n",
        "model.eval()\n",
        "X_drug = df_drug.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_drug = pca.transform(X_drug)\n",
        "\n",
        "output = (model(torch.from_numpy(X_drug).to(device).float())) > 0.5\n",
        "print( \"drugs\",output.sum().item())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================Train==================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0/3][500/2103]\tLoss_train: 137.4862\tTrain_Accuracy: 0.5273\n",
            "[0/3][1000/2103]\tLoss_train: 121.3252\tTrain_Accuracy: 0.5039\n",
            "[0/3][1500/2103]\tLoss_train: 96.5706\tTrain_Accuracy: 0.6523\n",
            "[0/3][2000/2103]\tLoss_train: 86.5863\tTrain_Accuracy: 0.7539\n",
            "Train Active accuracy 1.0 <---------------\n",
            "Train Inactive accuracy 0.6110961421544243\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[0/3][3/5]\tLoss_test: 96.0512\tTest_Accuracy: 0.5781\n",
            "Test Active accuracy 0.74 <---------------\n",
            "Test Inactive accuracy 0.584\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[1/3][500/2103]\tLoss_train: 45.5133\tTrain_Accuracy: 0.8594\n",
            "[1/3][1000/2103]\tLoss_train: 26.2961\tTrain_Accuracy: 0.9023\n",
            "[1/3][1500/2103]\tLoss_train: 34.3761\tTrain_Accuracy: 0.9062\n",
            "[1/3][2000/2103]\tLoss_train: 25.3864\tTrain_Accuracy: 0.9062\n",
            "Train Active accuracy 1.0 <---------------\n",
            "Train Inactive accuracy 0.8594034985906152\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[1/3][3/5]\tLoss_test: 63.5980\tTest_Accuracy: 0.8594\n",
            "Test Active accuracy 0.46 <---------------\n",
            "Test Inactive accuracy 0.853\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[2/3][500/2103]\tLoss_train: 25.7564\tTrain_Accuracy: 0.9375\n",
            "[2/3][1000/2103]\tLoss_train: 17.3119\tTrain_Accuracy: 0.9531\n",
            "[2/3][1500/2103]\tLoss_train: 26.5558\tTrain_Accuracy: 0.9609\n",
            "[2/3][2000/2103]\tLoss_train: 11.6240\tTrain_Accuracy: 0.9453\n",
            "Train Active accuracy 1.0 <---------------\n",
            "Train Inactive accuracy 0.866902945890676\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[2/3][3/5]\tLoss_test: 82.4680\tTest_Accuracy: 0.8555\n",
            "Test Active accuracy 0.48 <---------------\n",
            "Test Inactive accuracy 0.855\n",
            "=========================================================================\n",
            "drugs 326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV7RcaJ3WkNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "efc5ed0b-92c1-4844-d34f-601b358e7861"
      },
      "source": [
        "_,_,_=compute_roc(Y_test,model(torch.from_numpy(X_test).to(device).float()).cpu().detach().numpy())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHC1gdPsW15N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8ef83814-f7f9-453b-d6a2-99ebc597916f"
      },
      "source": [
        "ans = output.cpu().detach().numpy()\n",
        "result = np.where(ans == True)\n",
        "drug_df = pd.read_csv('Drug1.csv')\n",
        "list_df = drug_df[['DRUGBANK_ID']]\n",
        "list_df = list_df.iloc[result[0].tolist()]\n",
        "conf = model(torch.from_numpy(X_drug).to(device).float()).cpu().detach().numpy()\n",
        "drug_checker(result[0],conf)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drug number  928  score  [0.9996351]\n",
            "Drug number  1260  score  [0.986099]\n",
            "Drug number  573  score  [0.93566203]\n",
            "Drug number  383  score  [0.9998247]\n",
            "Drug number  1112  score  [0.97640413]\n",
            "Drug number  1918  score  [0.9993851]\n",
            "Drug number  1750  score  [0.9959188]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGygFbTe8j2O",
        "colab_type": "text"
      },
      "source": [
        "# Inception Network with BCE_loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX43qmJIW-c3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "be369db7-e1ce-4226-b0a4-427d034dea7b"
      },
      "source": [
        "num_epochs = 4\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "model = Covidcep()\n",
        "model = model.to(device).float()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 5e-5)\n",
        "\n",
        "for epoch in range(0, num_epochs ):\n",
        "    a, _,c = train(epoch,train_loader,writer)\n",
        "    i,_,e = test(epoch,test_loader)\n",
        "    \n",
        "model.eval()\n",
        "X_drug = df_drug.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_drug = pca.transform(X_drug)\n",
        "\n",
        "output = (model(torch.from_numpy(X_drug).to(device).float())) > 0.5\n",
        "print( \"drugs\",output.sum().item())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================Train==================================\n",
            "[0/4][500/2103]\tLoss_train: 0.6717\tTrain_Accuracy: 0.6055\n",
            "[0/4][1000/2103]\tLoss_train: 0.6794\tTrain_Accuracy: 0.5742\n",
            "[0/4][1500/2103]\tLoss_train: 0.6791\tTrain_Accuracy: 0.5625\n",
            "[0/4][2000/2103]\tLoss_train: 0.6560\tTrain_Accuracy: 0.6289\n",
            "Train Active accuracy 0.36056338028169016 <---------------\n",
            "Train Inactive accuracy 0.8108868070524512\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[0/4][3/5]\tLoss_test: 0.5986\tTest_Accuracy: 0.7617\n",
            "Test Active accuracy 0.5 <---------------\n",
            "Test Inactive accuracy 0.783\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[1/4][500/2103]\tLoss_train: 0.6499\tTrain_Accuracy: 0.5938\n",
            "[1/4][1000/2103]\tLoss_train: 0.6783\tTrain_Accuracy: 0.5742\n",
            "[1/4][1500/2103]\tLoss_train: 0.6672\tTrain_Accuracy: 0.5703\n",
            "[1/4][2000/2103]\tLoss_train: 0.6555\tTrain_Accuracy: 0.6250\n",
            "Train Active accuracy 0.36901408450704226 <---------------\n",
            "Train Inactive accuracy 0.821339744652628\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[1/4][3/5]\tLoss_test: 0.5914\tTest_Accuracy: 0.7695\n",
            "Test Active accuracy 0.5 <---------------\n",
            "Test Inactive accuracy 0.791\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[2/4][500/2103]\tLoss_train: 0.6386\tTrain_Accuracy: 0.6133\n",
            "[2/4][1000/2103]\tLoss_train: 0.6688\tTrain_Accuracy: 0.5898\n",
            "[2/4][1500/2103]\tLoss_train: 0.6558\tTrain_Accuracy: 0.6016\n",
            "[2/4][2000/2103]\tLoss_train: 0.6506\tTrain_Accuracy: 0.6445\n",
            "Train Active accuracy 0.447887323943662 <---------------\n",
            "Train Inactive accuracy 0.795590836235008\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[2/4][3/5]\tLoss_test: 0.5830\tTest_Accuracy: 0.7734\n",
            "Test Active accuracy 0.58 <---------------\n",
            "Test Inactive accuracy 0.772\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[3/4][500/2103]\tLoss_train: 0.6241\tTrain_Accuracy: 0.6523\n",
            "[3/4][1000/2103]\tLoss_train: 0.6527\tTrain_Accuracy: 0.6016\n",
            "[3/4][1500/2103]\tLoss_train: 0.6418\tTrain_Accuracy: 0.6094\n",
            "[3/4][2000/2103]\tLoss_train: 0.6432\tTrain_Accuracy: 0.6367\n",
            "Train Active accuracy 0.476056338028169 <---------------\n",
            "Train Inactive accuracy 0.7644012877908584\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[3/4][3/5]\tLoss_test: 0.5767\tTest_Accuracy: 0.7461\n",
            "Test Active accuracy 0.52 <---------------\n",
            "Test Inactive accuracy 0.744\n",
            "=========================================================================\n",
            "drugs 429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HZY75kuYx3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "264c16fe-8839-4cea-e277-cd86f4a6067d"
      },
      "source": [
        "_,_,_=compute_roc(Y_test,model(torch.from_numpy(X_test).to(device).float()).cpu().detach().numpy())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21YFelpAY2bm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a3fdc642-caa5-40f9-c032-3894ef9c8691"
      },
      "source": [
        "ans = output.cpu().detach().numpy()\n",
        "result = np.where(ans == True)\n",
        "drug_df = pd.read_csv('Drug1.csv')\n",
        "list_df = drug_df[['DRUGBANK_ID']]\n",
        "list_df = list_df.iloc[result[0].tolist()]\n",
        "conf = model(torch.from_numpy(X_drug).to(device).float()).cpu().detach().numpy()\n",
        "drug_checker(result[0],conf)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drug number  1082  score  [0.81924504]\n",
            "Drug number  928  score  [0.9250704]\n",
            "Drug number  115  score  [0.60907644]\n",
            "Drug number  1260  score  [0.68611497]\n",
            "Drug number  573  score  [0.56763256]\n",
            "Drug number  1133  score  [0.5014511]\n",
            "Drug number  383  score  [0.93591195]\n",
            "Drug number  1112  score  [0.6336284]\n",
            "Drug number  1919  score  [0.9630061]\n",
            "Drug number  1918  score  [0.9759523]\n",
            "Drug number  1750  score  [0.9666844]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7BxHGnBZEsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}