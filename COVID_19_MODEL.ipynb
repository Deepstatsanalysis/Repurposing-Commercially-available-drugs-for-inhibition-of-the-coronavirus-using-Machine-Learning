{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-19_MODEL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwh5Qt4YWJpuwa8Z+fvXiV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VIGNESHinZONE/Repurposing-Commercially-available-drugs-for-inhibition-of-the-coronavirus-using-Machine-Learning/blob/master/COVID_19_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVHtpQ19EmPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75834315-56d3-4d1d-b43e-b0a95c68a4ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK6eUMwdEtVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "515a0258-4efb-4702-efbe-b16ef32252dd"
      },
      "source": [
        "cd gdrive/My Drive/SOVID - 19\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/My Drive/SOVID - 19'\n",
            "/content/gdrive/.shortcut-targets-by-id/1FSDwqpFkKZ8yDznalDgKTEbZSsiUc4Wy/COVID - 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn-Itko9E2S3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "955d1fbc-2367-4761-9cf9-13e875dd061d"
      },
      "source": [
        "#General purpose libraries\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Torch Libraries for ANN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "#Sklearn Libraries for Preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7PDjFpOFAEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed= 12321\n",
        "random.seed(seed)  \n",
        "np.random.seed(0)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyZL8oJlFCCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "8e3b1604-73f6-4228-bb0a-9c8250f14d05"
      },
      "source": [
        "data_train = pd.read_csv('Training_Data_SamR_700.csv').drop(['Unnamed: 0'],axis=1)\n",
        "data_test = pd.read_csv('Testing_data.csv').drop(['Unnamed: 0'],axis=1)\n",
        "data_active_test = data_test[data_test['Outcome']==1]\n",
        "df_drug = pd.read_csv('Drugs.csv')\n",
        "\n",
        "data_train.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NEG_01_NEG</th>\n",
              "      <th>NEG_02_NEG</th>\n",
              "      <th>NEG_03_NEG</th>\n",
              "      <th>NEG_04_NEG</th>\n",
              "      <th>NEG_05_NEG</th>\n",
              "      <th>NEG_06_NEG</th>\n",
              "      <th>NEG_07_NEG</th>\n",
              "      <th>NEG_01_POS</th>\n",
              "      <th>NEG_02_POS</th>\n",
              "      <th>NEG_03_POS</th>\n",
              "      <th>NEG_04_POS</th>\n",
              "      <th>NEG_05_POS</th>\n",
              "      <th>NEG_06_POS</th>\n",
              "      <th>NEG_07_POS</th>\n",
              "      <th>NEG_01_HBD</th>\n",
              "      <th>NEG_02_HBD</th>\n",
              "      <th>NEG_03_HBD</th>\n",
              "      <th>NEG_04_HBD</th>\n",
              "      <th>NEG_05_HBD</th>\n",
              "      <th>NEG_06_HBD</th>\n",
              "      <th>NEG_07_HBD</th>\n",
              "      <th>NEG_01_HBA</th>\n",
              "      <th>NEG_02_HBA</th>\n",
              "      <th>NEG_03_HBA</th>\n",
              "      <th>NEG_04_HBA</th>\n",
              "      <th>NEG_05_HBA</th>\n",
              "      <th>NEG_06_HBA</th>\n",
              "      <th>NEG_07_HBA</th>\n",
              "      <th>NEG_01_ARC</th>\n",
              "      <th>NEG_02_ARC</th>\n",
              "      <th>NEG_03_ARC</th>\n",
              "      <th>NEG_04_ARC</th>\n",
              "      <th>NEG_05_ARC</th>\n",
              "      <th>NEG_06_ARC</th>\n",
              "      <th>NEG_07_ARC</th>\n",
              "      <th>NEG_01_HYP</th>\n",
              "      <th>NEG_02_HYP</th>\n",
              "      <th>NEG_03_HYP</th>\n",
              "      <th>NEG_04_HYP</th>\n",
              "      <th>NEG_05_HYP</th>\n",
              "      <th>...</th>\n",
              "      <th>HYP_01_HYP</th>\n",
              "      <th>HYP_02_HYP</th>\n",
              "      <th>HYP_03_HYP</th>\n",
              "      <th>HYP_04_HYP</th>\n",
              "      <th>HYP_05_HYP</th>\n",
              "      <th>HYP_06_HYP</th>\n",
              "      <th>HYP_07_HYP</th>\n",
              "      <th>WBN_GC_L_0.25</th>\n",
              "      <th>WBN_GC_H_0.25</th>\n",
              "      <th>WBN_GC_L_0.50</th>\n",
              "      <th>WBN_GC_H_0.50</th>\n",
              "      <th>WBN_GC_L_0.75</th>\n",
              "      <th>WBN_GC_H_0.75</th>\n",
              "      <th>WBN_GC_L_1.00</th>\n",
              "      <th>WBN_GC_H_1.00</th>\n",
              "      <th>WBN_EN_L_0.25</th>\n",
              "      <th>WBN_EN_H_0.25</th>\n",
              "      <th>WBN_EN_L_0.50</th>\n",
              "      <th>WBN_EN_H_0.50</th>\n",
              "      <th>WBN_EN_L_0.75</th>\n",
              "      <th>WBN_EN_H_0.75</th>\n",
              "      <th>WBN_EN_L_1.00</th>\n",
              "      <th>WBN_EN_H_1.00</th>\n",
              "      <th>WBN_LP_L_0.25</th>\n",
              "      <th>WBN_LP_H_0.25</th>\n",
              "      <th>WBN_LP_L_0.50</th>\n",
              "      <th>WBN_LP_H_0.50</th>\n",
              "      <th>WBN_LP_L_0.75</th>\n",
              "      <th>WBN_LP_H_0.75</th>\n",
              "      <th>WBN_LP_L_1.00</th>\n",
              "      <th>WBN_LP_H_1.00</th>\n",
              "      <th>XLogP</th>\n",
              "      <th>PSA</th>\n",
              "      <th>NumRot</th>\n",
              "      <th>NumHBA</th>\n",
              "      <th>NumHBD</th>\n",
              "      <th>MW</th>\n",
              "      <th>BBB</th>\n",
              "      <th>BadGroup</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.21896</td>\n",
              "      <td>1.89332</td>\n",
              "      <td>-2.33560</td>\n",
              "      <td>2.37617</td>\n",
              "      <td>-2.81410</td>\n",
              "      <td>3.18823</td>\n",
              "      <td>-3.64319</td>\n",
              "      <td>4.07620</td>\n",
              "      <td>-0.825457</td>\n",
              "      <td>1.36905</td>\n",
              "      <td>-1.69757</td>\n",
              "      <td>2.19638</td>\n",
              "      <td>-2.58817</td>\n",
              "      <td>3.09319</td>\n",
              "      <td>-3.48695</td>\n",
              "      <td>4.01060</td>\n",
              "      <td>-1.108000</td>\n",
              "      <td>1.15249</td>\n",
              "      <td>-1.84816</td>\n",
              "      <td>2.05047</td>\n",
              "      <td>-2.70698</td>\n",
              "      <td>2.96847</td>\n",
              "      <td>-3.59439</td>\n",
              "      <td>3.89453</td>\n",
              "      <td>1.111</td>\n",
              "      <td>90.29</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>369.421</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.05861</td>\n",
              "      <td>2.95213</td>\n",
              "      <td>-2.30022</td>\n",
              "      <td>3.16579</td>\n",
              "      <td>-2.79125</td>\n",
              "      <td>3.49171</td>\n",
              "      <td>-3.46407</td>\n",
              "      <td>4.01080</td>\n",
              "      <td>-0.774518</td>\n",
              "      <td>2.40204</td>\n",
              "      <td>-1.56260</td>\n",
              "      <td>2.67865</td>\n",
              "      <td>-2.35827</td>\n",
              "      <td>3.27843</td>\n",
              "      <td>-3.16100</td>\n",
              "      <td>4.16512</td>\n",
              "      <td>-1.080980</td>\n",
              "      <td>1.07652</td>\n",
              "      <td>-1.91118</td>\n",
              "      <td>1.92376</td>\n",
              "      <td>-2.75759</td>\n",
              "      <td>2.80998</td>\n",
              "      <td>-3.61043</td>\n",
              "      <td>3.71094</td>\n",
              "      <td>3.728</td>\n",
              "      <td>118.91</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>455.414</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.79896</td>\n",
              "      <td>1.23804</td>\n",
              "      <td>-1.94987</td>\n",
              "      <td>1.97407</td>\n",
              "      <td>-2.47040</td>\n",
              "      <td>2.79017</td>\n",
              "      <td>-3.16799</td>\n",
              "      <td>3.63023</td>\n",
              "      <td>-0.775963</td>\n",
              "      <td>1.24417</td>\n",
              "      <td>-1.55582</td>\n",
              "      <td>1.97668</td>\n",
              "      <td>-2.33738</td>\n",
              "      <td>2.80082</td>\n",
              "      <td>-3.11984</td>\n",
              "      <td>3.64791</td>\n",
              "      <td>-0.806244</td>\n",
              "      <td>1.15738</td>\n",
              "      <td>-1.45299</td>\n",
              "      <td>2.00033</td>\n",
              "      <td>-2.15199</td>\n",
              "      <td>2.85873</td>\n",
              "      <td>-2.87913</td>\n",
              "      <td>3.72070</td>\n",
              "      <td>3.332</td>\n",
              "      <td>42.43</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>269.324</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.53969</td>\n",
              "      <td>1.34274</td>\n",
              "      <td>-1.97551</td>\n",
              "      <td>2.07075</td>\n",
              "      <td>-2.75206</td>\n",
              "      <td>2.89920</td>\n",
              "      <td>-3.56623</td>\n",
              "      <td>3.75631</td>\n",
              "      <td>-0.781611</td>\n",
              "      <td>1.36371</td>\n",
              "      <td>-1.58847</td>\n",
              "      <td>2.14600</td>\n",
              "      <td>-2.41639</td>\n",
              "      <td>2.98943</td>\n",
              "      <td>-3.25765</td>\n",
              "      <td>3.85439</td>\n",
              "      <td>-1.035250</td>\n",
              "      <td>1.10898</td>\n",
              "      <td>-1.82384</td>\n",
              "      <td>1.92912</td>\n",
              "      <td>-2.66065</td>\n",
              "      <td>2.78327</td>\n",
              "      <td>-3.51047</td>\n",
              "      <td>3.65414</td>\n",
              "      <td>3.062</td>\n",
              "      <td>53.75</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>221.239</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.04825</td>\n",
              "      <td>1.35043</td>\n",
              "      <td>-1.62054</td>\n",
              "      <td>1.89552</td>\n",
              "      <td>-2.39049</td>\n",
              "      <td>2.55731</td>\n",
              "      <td>-3.17911</td>\n",
              "      <td>3.33711</td>\n",
              "      <td>-0.786468</td>\n",
              "      <td>1.30484</td>\n",
              "      <td>-1.57620</td>\n",
              "      <td>1.91242</td>\n",
              "      <td>-2.36748</td>\n",
              "      <td>2.62653</td>\n",
              "      <td>-3.15964</td>\n",
              "      <td>3.40169</td>\n",
              "      <td>-0.815247</td>\n",
              "      <td>1.11659</td>\n",
              "      <td>-1.40252</td>\n",
              "      <td>1.92860</td>\n",
              "      <td>-2.14519</td>\n",
              "      <td>2.74539</td>\n",
              "      <td>-2.92380</td>\n",
              "      <td>3.56424</td>\n",
              "      <td>6.358</td>\n",
              "      <td>50.41</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>313.470</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 180 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   NEG_01_NEG  NEG_02_NEG  NEG_03_NEG  ...  BBB  BadGroup  Outcome\n",
              "0           0           0           0  ...    0         1      0.0\n",
              "1           0           0           0  ...    0         0      1.0\n",
              "2           0           0           0  ...    1         0      1.0\n",
              "3           0           0           0  ...    1         0      0.0\n",
              "4           0           0           0  ...    1         4      1.0\n",
              "\n",
              "[5 rows x 180 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTXN4hthFWX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = data_train[['Outcome']].to_numpy()\n",
        "X_train = data_train.drop(['Outcome'],axis=1).to_numpy()\n",
        "\n",
        "\n",
        "Y_test = data_test[['Outcome']].to_numpy()\n",
        "X_test = data_test.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_test_active = data_active_test.drop(['Outcome'],axis=1).to_numpy()\n",
        "data_inactive_test = data_test[data_test['Outcome']==0]\n",
        "data_active_train = data_train[data_train['Outcome']==1]\n",
        "data_inactive_train = data_train[data_train['Outcome']==0]\n",
        "X_test_inactive = data_inactive_test.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_train_active = data_active_train.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_train_inactive = data_inactive_train.drop(['Outcome'],axis=1).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L01R0JltF03j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fd106348-f351-4b4c-e3ef-4e928f2a3460"
      },
      "source": [
        "X_train.shape , Y_train.shape , X_train_active.shape , X_train_inactive.shape , Y_test.shape , X_test.shape , X_test_active.shape , X_test_inactive.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((538343, 179),\n",
              " (538343, 1),\n",
              " (248855, 179),\n",
              " (289488, 179),\n",
              " (1050, 1),\n",
              " (1050, 179),\n",
              " (50, 179),\n",
              " (1000, 179))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gtNDbx-GCG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=128)\n",
        "pca.fit(X_train)\n",
        "\n",
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "X_test_active = pca.transform(X_test_active)\n",
        "X_test_inactive = pca.transform(X_test_inactive)\n",
        "X_train_active = pca.transform(X_train_active)\n",
        "X_train_inactive = pca.transform(X_train_inactive)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1XHUO3pJsVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters\n",
        "activation = 'relu'\n",
        "optimizer = 'Adam'\n",
        "batch_size = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "log_directory = \"runs/logs1\"\n",
        "step = 0\n",
        "writer = SummaryWriter(log_directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX5bjdj9Gwtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Covid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Covid, self).__init__()    \n",
        "                               \n",
        "    self.layer1 = nn.Sequential(nn.Linear(128,512),nn.ReLU(True))\n",
        "    self.layer1_1 = nn.Sequential(nn.Linear(512,1024),nn.ReLU(True))\n",
        "    self.layer2 = nn.Sequential(nn.Linear(1024,512),nn.ReLU(True))\n",
        "    self.layer3 = nn.Sequential(nn.Linear(512,256),nn.ReLU(True))\n",
        "    self.layer4 = nn.Sequential(nn.Linear(256,100),nn.ReLU(True))\n",
        "    self.layer5 = nn.Sequential(nn.Linear(100,1),nn.Sigmoid())\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "\n",
        "  def forward(self,input):\n",
        "\n",
        "    x = (self.layer1(input))\n",
        "    x = self.dropout(self.layer1_1(x))\n",
        "    x = self.dropout(self.layer2(x))\n",
        "    x = self.dropout(self.layer3(x))\n",
        "    x = self.dropout(self.layer4(x))\n",
        "    x = self.layer5(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class Covidcep(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Covidcep, self).__init__()\n",
        "    \n",
        "           \n",
        "    self.layer1_1 =  nn.Sequential(nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3,padding=1,stride=2),nn.ReLU(True))\n",
        "    self.layer1_2 =  nn.Sequential(nn.Conv1d(1, 4, kernel_size=5,padding=2,stride=2),nn.ReLU(True))\n",
        "    self.layer1_3 = nn.Sequential(nn.Conv1d(1, 4, kernel_size=1,padding=0,stride=1),nn.ReLU(True),nn.MaxPool1d(3,2,1))\n",
        "    self.avgpool1 = nn.AvgPool1d(kernel_size=3,padding=1,stride=1)\n",
        "    \n",
        "    self.layer2_1 = m = nn.Sequential(nn.Conv1d(in_channels=12, out_channels=4, kernel_size=3,padding=1,stride=2),nn.ReLU(True))\n",
        "    self.layer2_2 = m = nn.Sequential(nn.Conv1d(12, 4, kernel_size=5,padding=2,stride=2),nn.ReLU(True))\n",
        "    self.layer2_3 = nn.Sequential(nn.Conv1d(12, 4, kernel_size=1,padding=0,stride=1),nn.ReLU(True),nn.MaxPool1d(3,2,1))\n",
        "    self.avgpool2 = nn.AvgPool1d(kernel_size=3,padding=1,stride=1)\n",
        "         \n",
        "    self.layer3_1 = m = nn.Sequential(nn.Conv1d(in_channels=12, out_channels=3, kernel_size=3,padding=1,stride=2),nn.ReLU(True))\n",
        "    self.layer3_2 = m = nn.Sequential(nn.Conv1d(12, 3, kernel_size=5,padding=2,stride=2),nn.ReLU(True))\n",
        "    self.layer3_3 = nn.Sequential(nn.Conv1d(12, 3, kernel_size=1,padding=0,stride=1),nn.ReLU(True),nn.MaxPool1d(3,2,1))\n",
        "    self.avgpool3 = nn.AvgPool1d(kernel_size=3,padding=1,stride=1)   \n",
        "    \n",
        "    self.layer4 = nn.Sequential(nn.Linear(144,10),nn.ReLU(True))\n",
        "    self.layer5 = nn.Sequential(nn.Linear(10,1),nn.Sigmoid())\n",
        "\n",
        "  def forward(self,x):\n",
        "    \n",
        "    x = torch.unsqueeze(x,1).float()\n",
        "    x = self.avgpool1(torch.cat((self.layer1_1(x), self.layer1_2(x) ,self.layer1_3(x)), 1) )\n",
        "    x = self.avgpool2(torch.cat((self.layer2_1(x), self.layer2_2(x),self.layer2_3(x)), 1) )\n",
        "    x = self.avgpool3(torch.cat((self.layer3_1(x), self.layer3_2(x),self.layer3_3(x)), 1) )\n",
        "    x = x.view(x.size(0),-1).float()\n",
        "    x = self.layer4(x)\n",
        "    x = self.layer5(x)   \n",
        "    \n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjsJiwk5JOF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=3, weight=5 , logits=False, reduce=False ):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.logits = logits\n",
        "        self.weight = weight\n",
        "        self.reduce = reduce\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False , weight=targets*self.weight + 1)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "\n",
        "        if self.reduce:\n",
        "            return torch.mean(F_loss)\n",
        "        else:\n",
        "            return torch.sum(F_loss)\n",
        "\n",
        "def train(epoch,train_loader,writer):\n",
        "  model.train()\n",
        "  for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "  train_loss = 0.0\n",
        "  running_loss = 0.0\n",
        "  running_total = 0.0\n",
        "  running_accuracy = 0.0\n",
        "  total = 0.0\n",
        "  accuracy = 0.0\n",
        "  step = 1\n",
        "  print(\"==================================Train==================================\")\n",
        "  for i,data in enumerate(train_loader):\n",
        "    \n",
        "\n",
        "    model.zero_grad()\n",
        "    X_real,Y_real = data\n",
        "    X_real = X_real.to(device).float()\n",
        "    Y_real = Y_real.to(device).float()\n",
        "    b_size = X_real.size(0)\n",
        "    output = model(X_real.float()).float()\n",
        "    \n",
        "    loss = criterion(output.float(), Y_real.float())\n",
        "    loss.backward()\n",
        "    train_loss += loss.item()\n",
        "    running_loss += loss.item()\n",
        "    total += b_size\n",
        "    running_total += b_size\n",
        "\n",
        "\n",
        "    #accuracy\n",
        "    acc = ((Y_real == 1)==((output) > 0.5))\n",
        "    acc = acc.sum().item()\n",
        "    accuracy += acc\n",
        "    running_accuracy += acc\n",
        "    optimizer.step()\n",
        "\n",
        "    if i% 100 == 0 and i!=0:\n",
        "      Tloss,_,_ = test(epoch,test_loader,p = False)\n",
        "      writer.add_scalar('Training_Loss ',\n",
        "                            running_loss/100,\n",
        "                            step )\n",
        "      \n",
        "      writer.add_scalar('Test_Loss ',\n",
        "                            running_accuracy/running_total,\n",
        "                            step )\n",
        "      running_loss = 0.0\n",
        "      running_total = 0.0\n",
        "      running_accuracy = 0.0\n",
        "      step+=1\n",
        "\n",
        "    if i% 500 == 0 and i!=0:\n",
        "      print('[%d/%d][%d/%d]\\tLoss_train: %.4f\\tTrain_Accuracy: %.4f'\n",
        "                  % (epoch, num_epochs, i, len(train_loader),\n",
        "                     loss.item(), acc/b_size))\n",
        "  output = (model(torch.from_numpy(X_train_active).to(device).float())) > 0.5\n",
        "  print(\"Train Active accuracy\" , output.sum().item()/ output.size(0),\"<---------------\")\n",
        "  output = (model(torch.from_numpy(X_train_inactive).to(device).float())) < 0.5\n",
        "  print(\"Train Inactive accuracy\" , output.sum().item()/ output.size(0))\n",
        "  print(\"=========================================================================\")\n",
        "  return train_loss , accuracy/total ,total\n",
        "\n",
        "\n",
        "def test(epoch,test_loader,p = True):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    total = 0.0\n",
        "    accuracy = 0.0\n",
        "    if p:\n",
        "      print(\"==================================Test==================================\")\n",
        "\n",
        "    for i,data in enumerate(test_loader):\n",
        "      X_real,Y_real = data\n",
        "      X_real = X_real.to(device)\n",
        "      Y_real = Y_real.to(device)\n",
        "      b_size = X_real.size(0)\n",
        "      output = model(X_real.float()).float()\n",
        "      loss = criterion(output.float(), Y_real.float())\n",
        "      test_loss += loss.item()\n",
        "      total += b_size\n",
        "\n",
        "      acc = ((Y_real == 1)==((output) > 0.5))\n",
        "      acc = acc.sum().item() / b_size\n",
        "      accuracy += acc\n",
        "\n",
        "      if i% 3 == 0 and i!=0 and p:\n",
        "        print('[%d/%d][%d/%d]\\tLoss_test: %.4f\\tTest_Accuracy: %.4f'\n",
        "                  % (epoch, num_epochs, i, len(test_loader),\n",
        "                     loss.item(), acc))\n",
        "      \n",
        "\n",
        "    output = (model(torch.from_numpy(X_test_active).to(device).float())) > 0.5\n",
        "    if p:\n",
        "      print(\"Test Active accuracy\" , output.sum().item()/ output.size(0),\"<---------------\")\n",
        "    output = (model(torch.from_numpy(X_test_inactive).to(device).float())) < 0.5\n",
        "    if p:\n",
        "      print(\"Test Inactive accuracy\" , output.sum().item()/ output.size(0))\n",
        "      print(\"=========================================================================\")\n",
        "    return test_loss,accuracy,total\n",
        "\n",
        "\n",
        "def compute_roc(y_true, y_pred, plot=True):\n",
        "    \"\"\"\n",
        "    TODO\n",
        "    :param y_true: ground truth\n",
        "    :param y_pred: predictions\n",
        "    :param plot:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_true, y_pred)\n",
        "    auc_score = metrics.auc(fpr, tpr)\n",
        "    if plot:\n",
        "        plt.figure(figsize=(7, 6))\n",
        "        plt.plot(fpr, tpr, color='blue',\n",
        "                 label='ROC (AUC = %0.4f)' % auc_score)\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.title(\"ROC Curve\")\n",
        "        plt.xlabel(\"FPR\")\n",
        "        plt.ylabel(\"TPR\")\n",
        "        plt.show()\n",
        "\n",
        "    return fpr, tpr, auc_score \n",
        "\n",
        "def drug_checker(arr,conf):\n",
        "  ls = [1082,928,115,1260,794,573,1133,383,1112,1919,1918,1750]\n",
        "  for e in  ls:\n",
        "    if e in arr:\n",
        "      print( \"Drug number \", e , \" score \", conf[e])\n",
        "\n",
        "def drug_checker_all(arr,conf):\n",
        "  ls = [1082,928,115,1260,794,573,1133,383,1112,1919,1918,1750]\n",
        "  for e in  ls:\n",
        "    \n",
        "      print( \"Drug number \", e , \" score \", conf[e])\n",
        "\n",
        "                  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBaHNvg1TN-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).float())\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test).float())\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gOTDg3ZM4pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "fb6b2954-2164-4d75-9e43-bb1c1450a590"
      },
      "source": [
        "num_epochs = 2\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "model = Covid()\n",
        "model = model.to(device).float()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 5e-5)\n",
        "\n",
        "for epoch in range(0, num_epochs ):\n",
        "    a, _,c = train(epoch,train_loader,writer)\n",
        "    i,_,e = test(epoch,test_loader)\n",
        "    \n",
        "model.eval()\n",
        "X_drug = df_drug.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_drug = pca.transform(X_drug)\n",
        "\n",
        "output = (model(torch.from_numpy(X_drug).to(device).float())) > 0.5\n",
        "print( \"drugs\",output.sum().item())"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================Train==================================\n",
            "[0/2][500/2103]\tLoss_train: 0.5824\tTrain_Accuracy: 0.7070\n",
            "[0/2][1000/2103]\tLoss_train: 0.4986\tTrain_Accuracy: 0.7383\n",
            "[0/2][1500/2103]\tLoss_train: 0.4069\tTrain_Accuracy: 0.7891\n",
            "[0/2][2000/2103]\tLoss_train: 0.3463\tTrain_Accuracy: 0.8242\n",
            "Train Active accuracy 0.9690140845070423 <---------------\n",
            "Train Inactive accuracy 0.793915464544299\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[0/2][3/5]\tLoss_test: 0.4559\tTest_Accuracy: 0.8086\n",
            "Test Active accuracy 0.64 <---------------\n",
            "Test Inactive accuracy 0.774\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[1/2][500/2103]\tLoss_train: 0.2631\tTrain_Accuracy: 0.9141\n",
            "[1/2][1000/2103]\tLoss_train: 0.1454\tTrain_Accuracy: 0.9648\n",
            "[1/2][1500/2103]\tLoss_train: 0.2003\tTrain_Accuracy: 0.8984\n",
            "[1/2][2000/2103]\tLoss_train: 0.1342\tTrain_Accuracy: 0.9492\n",
            "Train Active accuracy 0.9943661971830986 <---------------\n",
            "Train Inactive accuracy 0.9356933620737302\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[1/2][3/5]\tLoss_test: 0.1758\tTest_Accuracy: 0.9453\n",
            "Test Active accuracy 0.32 <---------------\n",
            "Test Inactive accuracy 0.939\n",
            "=========================================================================\n",
            "drugs 154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWWDilc2TBOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "74ab55df-2754-4a92-f992-440df7208a9a"
      },
      "source": [
        "_,_,_=compute_roc(Y_test,model(torch.from_numpy(X_test).to(device).float()).cpu().detach().numpy())"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY9yKAwATlUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "440d084b-912a-433e-96c2-cbc8eb43c5f4"
      },
      "source": [
        "ans = output.cpu().detach().numpy()\n",
        "result = np.where(ans == True)\n",
        "drug_df = pd.read_csv('Drug1.csv')\n",
        "list_df = drug_df[['DRUGBANK_ID']]\n",
        "list_df = list_df.iloc[result[0].tolist()]\n",
        "conf = model(torch.from_numpy(X_drug).to(device).float()).cpu().detach().numpy()\n",
        "drug_checker(result[0],conf)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drug number  928  score  [0.9925391]\n",
            "Drug number  1260  score  [0.6379057]\n",
            "Drug number  383  score  [0.9997899]\n",
            "Drug number  1918  score  [0.98022467]\n",
            "Drug number  1750  score  [0.9996809]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PysxTG2hWB15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "861c2856-e9c0-4052-8a97-08497429591f"
      },
      "source": [
        "num_epochs = 2\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "model = Covid()\n",
        "model = model.to(device).float()\n",
        "criterion = FocalLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 5e-5)\n",
        "\n",
        "for epoch in range(0, num_epochs ):\n",
        "    a, _,c = train(epoch,train_loader,writer)\n",
        "    i,_,e = test(epoch,test_loader)\n",
        "    \n",
        "model.eval()\n",
        "X_drug = df_drug.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_drug = pca.transform(X_drug)\n",
        "\n",
        "output = (model(torch.from_numpy(X_drug).to(device).float())) > 0.5\n",
        "print( \"drugs\",output.sum().item())"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================Train==================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0/2][500/2103]\tLoss_train: 137.4228\tTrain_Accuracy: 0.5273\n",
            "[0/2][1000/2103]\tLoss_train: 120.8692\tTrain_Accuracy: 0.5039\n",
            "[0/2][1500/2103]\tLoss_train: 97.6769\tTrain_Accuracy: 0.6406\n",
            "[0/2][2000/2103]\tLoss_train: 82.4939\tTrain_Accuracy: 0.7578\n",
            "Train Active accuracy 1.0 <---------------\n",
            "Train Inactive accuracy 0.5947534958271155\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[0/2][3/5]\tLoss_test: 95.8580\tTest_Accuracy: 0.5781\n",
            "Test Active accuracy 0.74 <---------------\n",
            "Test Inactive accuracy 0.577\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[1/2][500/2103]\tLoss_train: 48.4526\tTrain_Accuracy: 0.8672\n",
            "[1/2][1000/2103]\tLoss_train: 24.8515\tTrain_Accuracy: 0.9102\n",
            "[1/2][1500/2103]\tLoss_train: 40.1600\tTrain_Accuracy: 0.9102\n",
            "[1/2][2000/2103]\tLoss_train: 28.1296\tTrain_Accuracy: 0.8828\n",
            "Train Active accuracy 1.0 <---------------\n",
            "Train Inactive accuracy 0.8419727242580003\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[1/2][3/5]\tLoss_test: 68.9209\tTest_Accuracy: 0.8633\n",
            "Test Active accuracy 0.5 <---------------\n",
            "Test Inactive accuracy 0.843\n",
            "=========================================================================\n",
            "drugs 312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV7RcaJ3WkNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "5bb971d8-eb7a-4b3c-c65c-b64239ebe5a1"
      },
      "source": [
        "_,_,_=compute_roc(Y_test,model(torch.from_numpy(X_test).to(device).float()).cpu().detach().numpy())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHC1gdPsW15N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c9ae86a9-3d52-44f4-dcc6-e489f12b7857"
      },
      "source": [
        "ans = output.cpu().detach().numpy()\n",
        "result = np.where(ans == True)\n",
        "drug_df = pd.read_csv('Drug1.csv')\n",
        "list_df = drug_df[['DRUGBANK_ID']]\n",
        "list_df = list_df.iloc[result[0].tolist()]\n",
        "conf = model(torch.from_numpy(X_drug).to(device).float()).cpu().detach().numpy()\n",
        "drug_checker(result[0],conf)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drug number  928  score  [0.9930554]\n",
            "Drug number  1260  score  [0.8899599]\n",
            "Drug number  383  score  [0.9799197]\n",
            "Drug number  1112  score  [0.6329389]\n",
            "Drug number  1918  score  [0.9569589]\n",
            "Drug number  1750  score  [0.9643083]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX43qmJIW-c3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "d06065a1-a89c-4672-a69f-2e65b1074c6d"
      },
      "source": [
        "num_epochs = 4\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "model = Covidcep()\n",
        "model = model.to(device).float()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr = 5e-5)\n",
        "\n",
        "for epoch in range(0, num_epochs ):\n",
        "    a, _,c = train(epoch,train_loader,writer)\n",
        "    i,_,e = test(epoch,test_loader)\n",
        "    \n",
        "model.eval()\n",
        "X_drug = df_drug.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_drug = pca.transform(X_drug)\n",
        "\n",
        "output = (model(torch.from_numpy(X_drug).to(device).float())) > 0.5\n",
        "print( \"drugs\",output.sum().item())"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================Train==================================\n",
            "[0/4][500/2103]\tLoss_train: 0.6717\tTrain_Accuracy: 0.6055\n",
            "[0/4][1000/2103]\tLoss_train: 0.6794\tTrain_Accuracy: 0.5742\n",
            "[0/4][1500/2103]\tLoss_train: 0.6791\tTrain_Accuracy: 0.5625\n",
            "[0/4][2000/2103]\tLoss_train: 0.6560\tTrain_Accuracy: 0.6289\n",
            "Train Active accuracy 0.36056338028169016 <---------------\n",
            "Train Inactive accuracy 0.811211518266733\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[0/4][3/5]\tLoss_test: 0.5985\tTest_Accuracy: 0.7656\n",
            "Test Active accuracy 0.5 <---------------\n",
            "Test Inactive accuracy 0.784\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[1/4][500/2103]\tLoss_train: 0.6501\tTrain_Accuracy: 0.5938\n",
            "[1/4][1000/2103]\tLoss_train: 0.6783\tTrain_Accuracy: 0.5742\n",
            "[1/4][1500/2103]\tLoss_train: 0.6671\tTrain_Accuracy: 0.5703\n",
            "[1/4][2000/2103]\tLoss_train: 0.6555\tTrain_Accuracy: 0.6250\n",
            "Train Active accuracy 0.36901408450704226 <---------------\n",
            "Train Inactive accuracy 0.821885535842591\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[1/4][3/5]\tLoss_test: 0.5913\tTest_Accuracy: 0.7734\n",
            "Test Active accuracy 0.5 <---------------\n",
            "Test Inactive accuracy 0.792\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[2/4][500/2103]\tLoss_train: 0.6388\tTrain_Accuracy: 0.6133\n",
            "[2/4][1000/2103]\tLoss_train: 0.6689\tTrain_Accuracy: 0.5898\n",
            "[2/4][1500/2103]\tLoss_train: 0.6559\tTrain_Accuracy: 0.6016\n",
            "[2/4][2000/2103]\tLoss_train: 0.6505\tTrain_Accuracy: 0.6445\n",
            "Train Active accuracy 0.4450704225352113 <---------------\n",
            "Train Inactive accuracy 0.7957946443375892\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[2/4][3/5]\tLoss_test: 0.5834\tTest_Accuracy: 0.7695\n",
            "Test Active accuracy 0.58 <---------------\n",
            "Test Inactive accuracy 0.771\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[3/4][500/2103]\tLoss_train: 0.6229\tTrain_Accuracy: 0.6523\n",
            "[3/4][1000/2103]\tLoss_train: 0.6529\tTrain_Accuracy: 0.6016\n",
            "[3/4][1500/2103]\tLoss_train: 0.6416\tTrain_Accuracy: 0.6250\n",
            "[3/4][2000/2103]\tLoss_train: 0.6431\tTrain_Accuracy: 0.6367\n",
            "Train Active accuracy 0.4788732394366197 <---------------\n",
            "Train Inactive accuracy 0.7649401702315812\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[3/4][3/5]\tLoss_test: 0.5758\tTest_Accuracy: 0.7539\n",
            "Test Active accuracy 0.52 <---------------\n",
            "Test Inactive accuracy 0.743\n",
            "=========================================================================\n",
            "drugs 425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HZY75kuYx3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "eb31f2a7-c26d-453d-f701-20c9dfac8d34"
      },
      "source": [
        "_,_,_=compute_roc(Y_test,model(torch.from_numpy(X_test).to(device).float()).cpu().detach().numpy())"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21YFelpAY2bm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d393598e-b9c7-4181-f89b-079676566604"
      },
      "source": [
        "ans = output.cpu().detach().numpy()\n",
        "result = np.where(ans == True)\n",
        "drug_df = pd.read_csv('Drug1.csv')\n",
        "list_df = drug_df[['DRUGBANK_ID']]\n",
        "list_df = list_df.iloc[result[0].tolist()]\n",
        "conf = model(torch.from_numpy(X_drug).to(device).float()).cpu().detach().numpy()\n",
        "drug_checker(result[0],conf)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drug number  1082  score  [0.82770705]\n",
            "Drug number  928  score  [0.928608]\n",
            "Drug number  115  score  [0.60784936]\n",
            "Drug number  1260  score  [0.6849942]\n",
            "Drug number  573  score  [0.5688571]\n",
            "Drug number  1133  score  [0.5084858]\n",
            "Drug number  383  score  [0.9398771]\n",
            "Drug number  1112  score  [0.6368335]\n",
            "Drug number  1919  score  [0.9658662]\n",
            "Drug number  1918  score  [0.9766018]\n",
            "Drug number  1750  score  [0.96753913]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7NhSTbtY5TT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "e028f7eb-eec1-4082-ccb4-8a2a02875599"
      },
      "source": [
        "num_epochs = 4\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "model = Covidcep()\n",
        "model = model.to(device).float()\n",
        "criterion = FocalLoss(weight = 0)\n",
        "optimizer = optim.Adam(model.parameters(),lr = 5e-5)\n",
        "\n",
        "for epoch in range(0, num_epochs ):\n",
        "    a, _,c = train(epoch,train_loader,writer)\n",
        "    i,_,e = test(epoch,test_loader)\n",
        "    \n",
        "model.eval()\n",
        "X_drug = df_drug.drop(['Outcome'],axis=1).to_numpy()\n",
        "X_drug = pca.transform(X_drug)\n",
        "\n",
        "output = (model(torch.from_numpy(X_drug).to(device).float())) > 0.5\n",
        "print( \"drugs\",output.sum().item())"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================Train==================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0/4][500/2103]\tLoss_train: 21.2810\tTrain_Accuracy: 0.6055\n",
            "[0/4][1000/2103]\tLoss_train: 21.7546\tTrain_Accuracy: 0.5742\n",
            "[0/4][1500/2103]\tLoss_train: 21.6056\tTrain_Accuracy: 0.5703\n",
            "[0/4][2000/2103]\tLoss_train: 21.1613\tTrain_Accuracy: 0.6172\n",
            "Train Active accuracy 0.36901408450704226 <---------------\n",
            "Train Inactive accuracy 0.8140026529597082\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[0/4][3/5]\tLoss_test: 19.6637\tTest_Accuracy: 0.7695\n",
            "Test Active accuracy 0.48 <---------------\n",
            "Test Inactive accuracy 0.785\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[1/4][500/2103]\tLoss_train: 20.5945\tTrain_Accuracy: 0.6016\n",
            "[1/4][1000/2103]\tLoss_train: 21.3328\tTrain_Accuracy: 0.5938\n",
            "[1/4][1500/2103]\tLoss_train: 20.9442\tTrain_Accuracy: 0.6094\n",
            "[1/4][2000/2103]\tLoss_train: 20.7451\tTrain_Accuracy: 0.6367\n",
            "Train Active accuracy 0.4732394366197183 <---------------\n",
            "Train Inactive accuracy 0.7524526059802134\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[1/4][3/5]\tLoss_test: 19.2714\tTest_Accuracy: 0.7109\n",
            "Test Active accuracy 0.54 <---------------\n",
            "Test Inactive accuracy 0.717\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[2/4][500/2103]\tLoss_train: 19.8895\tTrain_Accuracy: 0.6445\n",
            "[2/4][1000/2103]\tLoss_train: 20.8000\tTrain_Accuracy: 0.6172\n",
            "[2/4][1500/2103]\tLoss_train: 20.6287\tTrain_Accuracy: 0.6094\n",
            "[2/4][2000/2103]\tLoss_train: 20.3956\tTrain_Accuracy: 0.6484\n",
            "Train Active accuracy 0.5352112676056338 <---------------\n",
            "Train Inactive accuracy 0.7223960924114299\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[2/4][3/5]\tLoss_test: 19.0142\tTest_Accuracy: 0.6797\n",
            "Test Active accuracy 0.64 <---------------\n",
            "Test Inactive accuracy 0.681\n",
            "=========================================================================\n",
            "==================================Train==================================\n",
            "[3/4][500/2103]\tLoss_train: 19.5752\tTrain_Accuracy: 0.6641\n",
            "[3/4][1000/2103]\tLoss_train: 20.5578\tTrain_Accuracy: 0.6250\n",
            "[3/4][1500/2103]\tLoss_train: 20.5600\tTrain_Accuracy: 0.6016\n",
            "[3/4][2000/2103]\tLoss_train: 20.0679\tTrain_Accuracy: 0.6719\n",
            "Train Active accuracy 0.5887323943661972 <---------------\n",
            "Train Inactive accuracy 0.7161782180953961\n",
            "=========================================================================\n",
            "==================================Test==================================\n",
            "[3/4][3/5]\tLoss_test: 18.7961\tTest_Accuracy: 0.6875\n",
            "Test Active accuracy 0.54 <---------------\n",
            "Test Inactive accuracy 0.677\n",
            "=========================================================================\n",
            "drugs 459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeUQ04WlZCY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "aea2b97c-2d04-48e9-dafe-f2d2f8cceebd"
      },
      "source": [
        "_,_,_=compute_roc(Y_test,model(torch.from_numpy(X_test).to(device).float()).cpu().detach().numpy())"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAGDCAYAAAC2tW7jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5SddX3v8feXBAwICCbBo4SYEBLIBRhguAQ0iSYiooSeFjVoCyg0PRbq9bigcqqInnVa2ipHidixdVk9TbiUVYiWiygEFbkkSAgQTAgBZQJISARKApKB7/lj7xkmk7mF2bd59vu11iz38+zf3vs7z5r44fc83/17IjORJKmIdql3AZIkVYshJ0kqLENOklRYhpwkqbAMOUlSYRlykqTCMuQkSYVlyElDEBGPRcSLEfFCRDwVEd+LiD17jDk+Im6JiP+KiOci4ocRMa3HmL0j4tKI+G35vR4pb4/p43MjIj4ZEQ9ExJaIaI+IqyPi0Gr+vtJwY8hJQ3dKZu4JtABHAH/d+UREzAR+DFwHvA2YCNwH3B4RB5bH7Ab8FJgOnATsDcwENgHH9PGZ/xf4FPBJ4M3AFOBa4P07W3xEjNzZ10jDRbjiifT6RcRjwDmZ+ZPy9iXA9Mx8f3n758D9mfmXPV53A7AxM8+IiHOA/w1MyswXBvGZk4FfAzMz8+4+xiwD/l9m/nN5+6xyne8obydwHvBpYCRwI7AlM/9nt/e4DrgtM78WEW8DvgnMAl4Avp6Z3xjEIZLqypmcVCERMQ54H7CuvL0HcDxwdS/DrwLeU348D7hxMAFXNhdo7yvgdsIfAccC04AlwIcjIgAiYl/gROCKiNgF+CGlGej+5c//dES8d4ifL1WdIScN3bUR8V/A48DTwJfK+99M6d/Yk7285kmg83rb6D7G9GVnx/fl/2Tm5sx8Efg5kMA7y8+dBtyRmU8ARwNjM/PizHw5M9cD3wEWVKAGqaoMOWno/igz9wLmAIfwWnj9HngVeGsvr3kr8Ez58aY+xvRlZ8f35fHOB1m6bnEFcHp510eAfys/fjvwtoh4tvMH+ALwlgrUIFWVISdVSGbeBnwP+Ify9hbgDuCDvQz/EKVmE4CfAO+NiDcO8qN+CoyLiNZ+xmwB9ui2/d96K7nH9hLgtIh4O6XTmNeU9z8OPJqZ+3T72SszTx5kvVLdGHJSZV0KvCciDi9vXwCcWW733ysi9o2Ir1LqnvxyecwPKAXJNRFxSETsEhGjI+ILEbFDkGTmw8C3gCURMScidouIURGxICIuKA9bCfxxROwREQcBZw9UeGbeS2l2+c/ATZn5bPmpu4H/iojzI2L3iBgRETMi4ujXc4CkWjLkpArKzI3A94Evlrd/AbwX+GNK19F+Q+lrBu8ohxWZ+QdKzSe/Bm4GnqcULGOAu/r4qE8ClwGLgGeBR4D/TqlBBODrwMvA74B/5bVTjwNZXK5lcbff6RXgA5S+IvEorwXhmwb5nlLd+BUCSVJhOZOTJBWWISdJKixDTpJUWIacJKmwDDlJUmENu9XHx4wZkxMmTKh3GZKkBnLPPfc8k5lje+4fdiE3YcIEVqxYUe8yJEkNJCJ+09t+T1dKkgrLkJMkFZYhJ0kqLENOklRYhpwkqbAMOUlSYRlykqTCMuQkSYVlyEmSCqtqIRcR342IpyPigT6ej4j4RkSsi4hVEXFktWqRJDWnas7kvgec1M/z7wMml38WApdXsRZJUhOq2tqVmfmziJjQz5BTge9nZgJ3RsQ+EfHWzHyyWjVJkqqvrQ0WLx7c2JYWuPTS6tVSz2ty+wOPd9tuL+/bQUQsjIgVEbFi48aNNSlOkvT6LF4MK1fWu4qSYXEXgsxsA9oAWltbs87lSJIG0NICy5bVu4r6zuQ2AAd02x5X3idJUkXUM+SWAmeUuyyPA57zepwkqZKqdroyIpYAc4AxEdEOfAnYFSAzvw1cD5wMrAO2Ah+rVi2SpOZUze7K0wd4PoFzq/X5kqSdszNdkf1ZubJ0Ta4RuOKJJAmoXFdkSwt85CNDf59KGBbdlZKk2miUrshKcSYnSSosQ06SVFiGnCSpsLwmJ0kVVqkuxVprpK7ISnEmJ0kV1khrN+6MRuqKrBRncpJUBUXrUhyunMlJkgrLkJMkFZYhJ0kqLK/JSWpq1eiELGKX4nDlTE5SU6tGJ2QRuxSHK2dykpqenZDF5UxOklRYhpwkqbAMOUlSYRlykppSWxvMmTM8l9/S4BlykppSZ1elnZDFZnelpKZlV2XxOZOTJBWWISdJKixDTpJUWF6TkzSsVGqtSdeXbA7O5CQNK5Vaa9KuyubgTE7SsGNXpAbLmZwkqbAMOUlSYRlykqTC8pqcpJoaanekXZHaGc7kJNXUULsj7YrUznAmJ6nm7I5UrTiTkyQVliEnSSosQ06SVFhek5NUUQN1T9odqVpyJiepogbqnrQ7UrXkTE5Sxdk9qUbhTE6SVFiGnCSpsAw5SVJhGXKSKqKtDebMqcwNTaVKMeQkVURnV6Xdk2okdldKqhi7KtVonMlJkgrLkJMkFZYhJ0kqLK/JSerVzt7B2zUp1YicyUnq1c7ewduuSjUiZ3KS+mS3pIa7qs7kIuKkiFgTEesi4oJenh8fEbdGxL0RsSoiTq5mPZKk5lK1kIuIEcAi4H3ANOD0iJjWY9j/Aq7KzCOABcC3qlWPJKn5VHMmdwywLjPXZ+bLwBXAqT3GJLB3+fGbgCeqWI8kqclU85rc/sDj3bbbgWN7jLkI+HFE/BXwRmBeFeuR1IfeOintllQR1Lu78nTge5k5DjgZ+EFE7FBTRCyMiBURsWLjxo01L1Iqut46Ke2WVBFUcya3ATig2/a48r7uzgZOAsjMOyJiFDAGeLr7oMxsA9oAWltbs1oFS83MTkoVUTVncsuByRExMSJ2o9RYsrTHmN8CcwEiYiowCnCqJkmqiKqFXGZ2AOcBNwEPUeqifDAiLo6I+eVhnwP+PCLuA5YAZ2WmMzVJUkVU9cvgmXk9cH2PfV/s9ng1cEI1a5AkNS9XPJGaSF/rUdpJqaKqd3elpBrqaz1KOylVVM7kpCZjF6WaiTM5SVJhGXKSpMIy5CRJheU1OanAenZT2kWpZuNMTiqwnt2UdlGq2TiTkwrObko1M2dykqTCMuQkSYVlyEmSCstrctIw1tdalJ3splSzcyYnDWN9rUXZyW5KNTtnctIwZ/ek1DdncpKkwjLkJEmFZchJkgrLkJMkFZYhJ0kqLENOklRYhpwkqbAMOUlSYfllcKlBDbRkF7hslzQQZ3JSgxpoyS5w2S5pIM7kpAbmkl3S0DiTkyQVliEnSSosQ06SVFhek5O6GUxHY63YOSkNnTM5qZvBdDTWip2T0tA5k5N6sKNRKg5ncpKkwjLkJEmFZchJkgrLkJModVXOmdM4TSeSKsOQk3itq9KORqlY7K6UyuyqlIrHmZwkqbAMOUlSYRlykqTCMuQkSYVlyEmSCsuQkyQVliEnSSosQ06SVFiGnCSpsFzxRIU3mLt9exduqZicyanwBnO3b9eslIrJmZyagutSSs3JmZwkqbCqGnIRcVJErImIdRFxQR9jPhQRqyPiwYgY4MqJJEmDV7XTlRExAlgEvAdoB5ZHxNLMXN1tzGTgr4ETMvP3EbFfteqRJDWfas7kjgHWZeb6zHwZuAI4tceYPwcWZebvATLz6SrWoybU1ga33VbvKiTVSzVDbn/g8W7b7eV93U0BpkTE7RFxZ0Sc1NsbRcTCiFgRESs2btxYpXJVRJ1fHbBzUmpO9W48GQlMBuYApwPfiYh9eg7KzLbMbM3M1rFjx9a4RA13s2fDwoX1rkJSPVQz5DYAB3TbHlfe1107sDQzt2Xmo8BaSqEnSdKQVTPklgOTI2JiROwGLACW9hhzLaVZHBExhtLpy/VVrEmS1ESqFnKZ2QGcB9wEPARclZkPRsTFETG/POwmYFNErAZuBT6fmZuqVZMkqblUdcWTzLweuL7Hvi92e5zAZ8s/UsV0rlfpmpRSc6t344lUFd0Dzs5KqXm5dqUKy/UqJTmTkyQVliEnSSosQ06SVFiGnAqlrQ3mzBn4JqmSmoMhp0Kxq1JSd3ZXqnDsqpTUyZmcJKmwDDlJUmEZcpKkwvKanBpe5zqUg+FalZK6cyanhtfZMTkYdlVK6s6ZnIYFOyYlvR7O5CRJhWXISZIKa6dDLiJ2iYiPVqMYSZIqqc9rchGxN3AusD+wFLgZOA/4HHAf8G+1KFDNpbdOSjsmJb1e/c3kfgAcDNwPnAPcCpwG/FFmnlqD2tSEeuuktGNS0uvVX3flgZl5KEBE/DPwJDA+M1+qSWVqWnZSSqqU/mZy2zofZOYrQLsBJ0kaTvqbyR0eEc8DUd7evdt2ZubeVa9OkqQh6DPkMnNELQuRJKnS+uuuHAX8D+AgYBXw3czsqFVhah7dOyrtpJRUSf1dk/tXoJVSd+XJwD/WpCI1ne4dlXZSSqqk/q7JTevWXfkvwN21KUnNyI5KSdUw2O5KT1NKkoad/mZyLeVuSih1VNpdKUkaVvoLufsy84iaVSJJUoX1F3JZsypUWIO5q7cdlZKqpb+Q2y8iPtvXk5n5tSrUo4Lp7JzsL8TsqJRULf2F3AhgT15b8UR6XeyclFQv/YXck5l5cc0qkSSpwvr7CoEzOEnSsNZfyM2tWRWSJFVBfws0b65lIRq6wXQy1pqdk5Lqqb+ZnIaZ3u6qXW92Tkqqp/4aTzQM2ckoSa9xJidJKixDTpJUWIacJKmwDLmCaGuD226rdxWS1FgMuYLo/OqAnYyS9BpDrkBmz4aFC+tdhSQ1DkNOklRYhpwkqbD8Mvgw1NvyXS6fJUk7ciY3DPW2fJfLZ0nSjpzJDVMu3yVJA3MmJ0kqrKqGXEScFBFrImJdRFzQz7g/iYiMiNZq1iNJai5VC7mIGAEsAt4HTANOj4hpvYzbC/gUcFe1apEkNadqXpM7BliXmesBIuIK4FRgdY9xXwH+Dvh8FWsZVga6+amdlJI0ONU8Xbk/8Hi37fbyvi4RcSRwQGb+Z39vFBELI2JFRKzYuHFj5SttMAPd/NROSkkanLp1V0bELsDXgLMGGpuZbUAbQGtra1a3ssZg96QkDV01Z3IbgAO6bY8r7+u0FzADWBYRjwHHAUttPpEkVUo1Q245MDkiJkbEbsACYGnnk5n5XGaOycwJmTkBuBOYn5krqliTJKmJVC3kMrMDOA+4CXgIuCozH4yIiyNifrU+V5KkTlW9JpeZ1wPX99j3xT7GzqlmLfU2UMdkd3ZPSlJluOJJjQzUMdmd3ZOSVBmuXVlDdkxKUm05k5MkFZYhJ0kqLENOklRYXpOrkp7dlHZMSlLtOZOrkp7dlHZMSlLtOZOrIrspJam+nMlJkgrLkJMkFZYhJ0kqLEOuCtra4Lbb6l2FJMmQq4LOrw7YTSlJ9WXIVcns2bBwYb2rkKTmZshJkgrLkJMkFZYhJ0kqLEOuwuyslKTGYchVmJ2VktQ4DLkqsLNSkhqDISdJKixDTpJUWIacJKmwDLkKaWuDOXO2v1GqJKm+DLkK6bwTuHcAl6TG4Z3BK8g7gUtSY3EmJ0kqLENOklRYhpwkqbAMuSHo7Ki0q1KSGpMhNwSdHZVgV6UkNSK7K4fIjkpJalzO5CRJhWXISZIKy5CTJBWWIbeT7KiUpOHDkNtJdlRK0vBhd+XrYEelJA0PzuQkSYVlyEmSCsuQkyQVltfkBtDWVmo26dR5Y1RJUuNzJjeA7t2UYEelJA0nzuQGwW5KSRqenMlJkgrLkJMkFZYhJ0kqLEOuD51rVLo+pSQNX4ZcHzq7Ku2mlKThy+7KfthVKUnDW1VnchFxUkSsiYh1EXFBL89/NiJWR8SqiPhpRLy9mvVIkppL1UIuIkYAi4D3AdOA0yNiWo9h9wKtmXkY8O/AJdWqR5LUfKo5kzsGWJeZ6zPzZeAK4NTuAzLz1szcWt68ExhXxXokSU2mmiG3P/B4t+328r6+nA3cUMV6JElNpiEaTyLiT4FWYHYfzy8EFgKMHz++hpVJkoazas7kNgAHdNseV963nYiYB1wIzM/MP/T2RpnZlpmtmdk6duzYqhQrSSqeaobccmByREyMiN2ABcDS7gMi4gjgnygF3NNVrEWS1ISqFnKZ2QGcB9wEPARclZkPRsTFETG/POzvgT2BqyNiZUQs7ePtJEnaaVW9JpeZ1wPX99j3xW6P51Xz8yVJzc1lvXrR1ga33VbvKiRJQ2XI9WLx4tL/umalJA1vhlwfZs+GhQvrXYUkaSgMOUlSYRlykqTCMuQkSYVlyHXj3cAlqVgMuW68G7gkFUtDLNDcSLwbuCQVhzM5SVJhGXKSpMIy5MpcykuSiseQK3MpL0kqHkOuG5fykqRiMeQkSYVlyEmSCsuQkyQVliEnSSosQ06SVFiGnCSpsAw5SVJhGXKSpMIy5CRJhWXISZIKy5CTJBWWISdJKixDTpJUWIacJKmwDDlJUmEZcpKkwjLkJEmFZchJkgrLkJMkFZYhJ0kqLENOklRYhpwkqbAMOUlSYRlykqTCMuQkSYVlyEmSCsuQkyQV1sh6F1APbW2wePH2+1auhJaW+tQjSaqOppzJLV5cCrXuWlrgIx+pTz2SpOpoypkclEJt2bJ6VyFJqqamnMlJkpqDISdJKqymPV0pqbFs27aN9vZ2XnrppXqXogY2atQoxo0bx6677jqo8YacpIbQ3t7OXnvtxYQJE4iIepejBpSZbNq0ifb2diZOnDio13i6UlJDeOmllxg9erQBpz5FBKNHj96p2b4hJ6lhGHAayM7+jRhykqTCqmrIRcRJEbEmItZFxAW9PP+GiLiy/PxdETGhmvVIUn9GjBhBS0sLM2bM4JRTTuHZZ5/teu7BBx/k3e9+NwcffDCTJ0/mK1/5CpnZ9fwNN9xAa2sr06ZN44gjjuBzn/tcr59x7bXXcvHFF2+3r6WlhQULFmy3b86cOaxYsaJr+7HHHmPGjBld23fffTezZs3i4IMP5ogjjuCcc85h69atQ/r9H330UY499lgOOuggPvzhD/Pyyy/3Om7VqlXMnDmT6dOnc+ihh3adPrzyyis57LDDmD59Oueff/52r7nqqquYNm0a06dP5yPdVt44//zzmTFjBjNmzODKK6/s2r9gwQIefvjhIf0+QOlCXjV+gBHAI8CBwG7AfcC0HmP+Evh2+fEC4MqB3veoo47KoZo9u/QjqXGsXr263iXkG9/4xq7HZ5xxRn71q1/NzMytW7fmgQcemDfddFNmZm7ZsiVPOumkvOyyyzIz8/77788DDzwwH3rooczM7OjoyG9961u9fsbMmTNz48aNXdurV6/OGTNm5Nve9rZ84YUXuvbPnj07ly9f3rX96KOP5vTp0zMz86mnnsrx48fnL3/5y67nr7766nzqqaeG9Pt/8IMfzCVLlmRm5l/8xV/0+jts27YtDz300Fy5cmVmZj7zzDPZ0dGRzzzzTB5wwAH59NNPZ2bp+P3kJz/JzMy1a9dmS0tLbt68OTMzf/e732Vm5o9+9KOcN29ebtu2LV944YVsbW3N5557LjMzly1bluecc06vdfb2twKsyF4yo5rdlccA6zJzPUBEXAGcCqzuNuZU4KLy438HLouIKBcsqUl9+tM7Lr03VC0tcOmlgx8/c+ZMVq1aBcDixYs54YQTOPHEEwHYY489uOyyy5gzZw7nnnsul1xyCRdeeCGHHHIIUJoRfuITn9jhPdeuXcsb3vAGxowZ07VvyZIl/Nmf/RkPPfQQ11133XaznL4sWrSIM888k5kzZ3btO+200wb/y/UiM7nllltYXF7Y98wzz+Siiy7a4ff48Y9/zGGHHcbhhx8OwOjRowFYv349kydPZuzYsQDMmzePa665hrlz5/Kd73yHc889l3333ReA/fbbD4DVq1cza9YsRo4cyciRIznssMO48cYb+dCHPsQ73/lOzjrrLDo6Ohg58vVHVTVPV+4PPN5tu728r9cxmdkBPAeM7vlGEbEwIlZExIqNGzcOubCWFhdjltS3V155hZ/+9KfMnz8fKJ2qPOqoo7YbM2nSJF544QWef/55HnjggR2e783tt9/OkUceud2+K6+8kgULFnD66aezZMmSQdU32M9bs2YNLS0tvf50PxULsGnTJvbZZ5+uQBk3bhwbNmzY4T3Xrl1LRPDe976XI488kksuuQSAgw46iDVr1vDYY4/R0dHBtddey+OPP971mrVr13LCCSdw3HHHceONNwJw+OGHc+ONN7J161aeeeYZbr311q7X7LLLLhx00EHcd999gzomfRkW35PLzDagDaC1tXXIs7yd+a85SbVXr3+jL774Ii0tLWzYsIGpU6fynve8p6Lv/+STT3bNdABWrFjBmDFjGD9+PPvvvz8f//jH2bx5M29+85t77SLc2c7Cgw8+mJUVnhJ3dHTwi1/8guXLl7PHHnswd+5cjjrqKObOncvll1/Ohz/8YXbZZReOP/54Hnnkka7XPPzwwyxbtoz29nZmzZrF/fffz4knnsjy5cs5/vjjGTt2LDNnzmTEiBFdn7XffvvxxBNPDCrQ+1LNmdwG4IBu2+PK+3odExEjgTcBm6pYkyT1affdd2flypX85je/ITNZtGgRANOmTeOee+7Zbuz69evZc8892XvvvZk+ffoOz/f1/t2/47VkyRJ+/etfM2HCBCZNmsTzzz/PNddcA5ROA/7+97/vGrt58+au05yD/bydmcmNHj2aZ599lo6ODqD05fz99+958q00w5s1axZjxoxhjz324OSTT+ZXv/oVAKeccgp33XUXd9xxBwcffDBTpkzpes38+fPZddddmThxIlOmTOlqKrnwwgtZuXIlN998M5nZ9RoofXdy9913H/D37FdvF+oq8UNplrgemMhrjSfTe4w5l+0bT64a6H0r0XgiqfE0WuPJr371qxw/fnxu27Ytt27dmhMnTsybb745M0uNKO9///vzG9/4RmZm3nfffTlp0qRcs2ZNZma+8sorefnll+/w/jfccEN+9KMf7Rozbty43LBhQ9fzt9xyS77rXe/KzMxvfvObecYZZ+Srr76amZmf/OQn88tf/nJmvtZ4cuedd3a99pprrhly48lpp522XePJokWLdhizefPmPOKII3LLli25bdu2nDt3bv7oRz/KzNcaSjZv3pyHH3541/G44YYb8owzzsjMzI0bN+a4ceO2a1jJLB3D6dOn57Zt27o+a8aMGfnkk0/uUMPONJ5ULeRKn8nJwFpKXZYXlvddDMwvPx4FXA2sA+4GDhzoPQ05qZgaLeQyMz/wgQ/k97///czMXLVqVc6ePTunTJmSkyZNyosuuqgrgDIzf/jDH+aRRx6ZhxxySE6dOjU///nP7/D+W7ZsyWnTpuWrr76ay5Yty2OPPXa75zs6OvItb3lLPvHEE/mHP/whzz333Dz00EPzsMMOy49//OO5ZcuWrrG//OUv8x3veEdOmTIlDznkkFy4cOF2z78ejzzySB599NE5adKkPO200/Kll17KzMzrrrsu/+Zv/qZr3A9+8IOcNm1aTp8+fbvfc8GCBTl16tScOnVqV1hmZr766qv5mc98JqdOnZozZszoeu7FF1/sGn/sscfmvffe2/Wap556Ko8++uhe69yZkIscZo2Mra2t2f27I5KK4aGHHmLq1Kn1LqPqPvWpT3HKKacwb968epfS0L7+9a+z9957c/bZZ+/wXG9/KxFxT2a29hzriieSVENf+MIXhvyl7Wawzz77cOaZZw75fYZFd6UkFcVb3vKWrq8mqG8f+9jHKvI+zuQkNYzhdvlEtbezfyOGnKSGMGrUKDZt2mTQqU+ZpfvJjRo1atCv8XSlpIYwbtw42tvbqcSqRiquzjuDD5YhJ6khdH5RWKokT1dKkgrLkJMkFZYhJ0kqrGG34klEbAR+U4G3GgM8U4H3KSKPTd88Nn3z2PTNY9O3Sh2bt2fm2J47h13IVUpErOhtCRh5bPrjsembx6ZvHpu+VfvYeLpSklRYhpwkqbCaOeTa6l1AA/PY9M1j0zePTd88Nn2r6rFp2mtykqTia+aZnCSp4AofchFxUkSsiYh1EXFBL8+/ISKuLD9/V0RMqH2V9TGIY/PZiFgdEasi4qcR8fZ61FkPAx2bbuP+JCIyIpqmc24wxyYiPlT+23kwIhbXusZ6GcS/qfERcWtE3Fv+d3VyPeqstYj4bkQ8HREP9PF8RMQ3ysdtVUQcWbEP7+124UX5AUYAjwAHArsB9wHTeoz5S+Db5ccLgCvrXXcDHZt3AXuUH3/CY7PDuL2AnwF3Aq31rrtRjg0wGbgX2Le8vV+9626gY9MGfKL8eBrwWL3rrtGxmQUcCTzQx/MnAzcAARwH3FWpzy76TO4YYF1mrs/Ml4ErgFN7jDkV+Nfy438H5kZE1LDGehnw2GTmrZnZeQvjO4HBL/09vA3m7wbgK8DfAS/Vsrg6G8yx+XNgUWb+HiAzn65xjfUymGOTwN7lx28CnqhhfXWTmT8DNvcz5FTg+1lyJ7BPRLy1Ep9d9JDbH3i823Z7eV+vYzKzA3gOGF2T6uprMMemu7Mp/ZdWMxjw2JRPpxyQmf9Zy8IawGD+bqYAUyLi9oi4MyJOqll19TWYY3MR8KcR0Q5cD/xVbUpreDv7/0eD5q12NKCI+FOgFZhd71oaQUTsAnwNOKvOpTSqkZROWc6hNPv/WUQcmpnP1rWqxnA68L3M/MeImAn8ICJmZOar9S6sqIo+k9sAHNBte1x5X69jImIkpVMIm2pSXX0N5tgQEfOAC4H5mfmHGtVWbwMdm72AGcCyiHiM0jWEpU3SfDKYv5t2YGlmbsvMR4G1lEKv6AZzbM4GrgLIzDuAUZTWbmx2g/r/o9ej6CG3HJgcERMjYjdKjSVLe4xZCpxZfnwacEuWr4QW3IDHJiKOAP6JUsA1y3UVGODYZOZzmTkmMydk5gRK1yvnZ+aK+pRbU4P5N3UtpVkcETGG0unL9bUssk4Gc2x+C8wFiIiplELOW6GXjtMZ5S7L44DnMvPJSrxxoU9XZmZHRJwH3ESp8+m7mflgRFwMrMjMpcC/UDplsI7ShSCZ5LMAAAGfSURBVNEF9au4dgZ5bP4e2BO4utyL89vMnF+3omtkkMemKQ3y2NwEnBgRq4FXgM9nZuHPjgzy2HwO+E5EfIZSE8pZzfAf1RGxhNJ/+IwpX4/8ErArQGZ+m9L1yZOBdcBW4GMV++wmOL6SpCZV9NOVkqQmZshJkgrLkJMkFZYhJ0kqLENOklRYhpzUoCLilYhY2e1nQkTMiYjnytsPRcSXymO77/91RPxDveuXGkGhvycnDXMvZmZL9x3lW0H9PDM/EBFvBFZGxA/LT3fu3x24NyL+IzNvr23JUmNxJicNU5m5BbgHOKjH/heBlVRogVtpODPkpMa1e7dTlf/R88mIGE1p3cwHe+zfl9JakT+rTZlS4/J0pdS4djhdWfbOiLgXeBX42/LSUXPK+++jFHCXZuZTNaxVakiGnDT8/DwzP9DX/oiYCNwZEVdl5spaFyc1Ek9XSgVTvr3N3wLn17sWqd4MOamYvg3MKndjSk3LuxBIkgrLmZwkqbAMOUlSYRlykqTCMuQkSYVlyEmSCsuQkyQVliEnSSosQ06SVFj/H3/6x/TqI4zVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_P8KBEJZERP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "163c4112-374b-4f27-cbfd-94557ed7b3b6"
      },
      "source": [
        "ans = output.cpu().detach().numpy()\n",
        "result = np.where(ans == True)\n",
        "drug_df = pd.read_csv('Drug1.csv')\n",
        "list_df = drug_df[['DRUGBANK_ID']]\n",
        "list_df = list_df.iloc[result[0].tolist()]\n",
        "conf = model(torch.from_numpy(X_drug).to(device).float()).cpu().detach().numpy()\n",
        "drug_checker(result[0],conf)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drug number  1082  score  [0.5930077]\n",
            "Drug number  928  score  [0.66844696]\n",
            "Drug number  115  score  [0.527417]\n",
            "Drug number  1260  score  [0.5245006]\n",
            "Drug number  573  score  [0.5099093]\n",
            "Drug number  383  score  [0.68512547]\n",
            "Drug number  1112  score  [0.53639066]\n",
            "Drug number  1919  score  [0.688115]\n",
            "Drug number  1918  score  [0.7613102]\n",
            "Drug number  1750  score  [0.73007894]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7BxHGnBZEsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}